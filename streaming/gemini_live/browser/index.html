<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AILANG √ó Gemini Live ‚Äî Text to Audio</title>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400;500;600;700&family=Outfit:wght@300;400;500;600;700&display=swap" rel="stylesheet">
<style>
  :root {
    --bg-void: #050506;
    --bg-deep: #0a0a0c;
    --bg-panel: #0f1012;
    --bg-raised: #151618;
    --bg-surface: #1b1c1f;
    --bg-hover: #222326;
    --border: #1e1f22;
    --border-warm: #2a2520;
    --border-active: #3a3530;
    --text: #c8c4bc;
    --text-muted: #706b62;
    --text-dim: #3d3a35;
    --amber: #d4a046;
    --amber-bright: #e8b85a;
    --amber-hot: #f0c464;
    --amber-glow: rgba(212,160,70,0.12);
    --amber-dim: rgba(212,160,70,0.06);
    --green: #4ade80;
    --green-dim: #0d2818;
    --red: #ef4444;
    --red-dim: #2a0f0f;
    --mono: 'JetBrains Mono', monospace;
    --display: 'Outfit', system-ui, sans-serif;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  html, body {
    height: 100%;
    background: var(--bg-void);
    color: var(--text);
    font-family: var(--mono);
    font-size: 13px;
    overflow: hidden;
    -webkit-font-smoothing: antialiased;
  }

  /* ‚îÄ‚îÄ Noise texture overlay ‚îÄ‚îÄ */
  body::before {
    content: '';
    position: fixed;
    inset: 0;
    z-index: 9999;
    pointer-events: none;
    opacity: 0.025;
    background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 256 256' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='n'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23n)'/%3E%3C/svg%3E");
    background-repeat: repeat;
    background-size: 256px;
  }

  /* ‚îÄ‚îÄ App grid ‚îÄ‚îÄ */
  .app {
    display: grid;
    grid-template-rows: auto auto 1fr auto auto;
    height: 100vh;
    max-width: 1200px;
    margin: 0 auto;
  }

  /* ‚îÄ‚îÄ Header ‚îÄ‚îÄ */
  .header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 14px 24px;
    border-bottom: 1px solid var(--border);
    background: linear-gradient(180deg, rgba(212,160,70,0.03) 0%, transparent 100%);
    animation: headerReveal 0.6s ease-out;
  }
  @keyframes headerReveal {
    from { opacity: 0; transform: translateY(-8px); }
    to { opacity: 1; transform: translateY(0); }
  }

  .header-left {
    display: flex;
    align-items: center;
    gap: 16px;
  }

  .logo {
    font-family: var(--display);
    font-size: 16px;
    font-weight: 600;
    color: var(--amber);
    letter-spacing: -0.3px;
  }
  .logo span {
    color: var(--text-dim);
    font-weight: 300;
    margin: 0 2px;
  }

  .badge {
    font-size: 9px;
    font-weight: 500;
    padding: 3px 8px;
    border-radius: 3px;
    text-transform: uppercase;
    letter-spacing: 0.8px;
  }
  .badge-model {
    background: var(--bg-surface);
    color: var(--text-muted);
    border: 1px solid var(--border);
  }
  .badge-wss {
    background: var(--green-dim);
    color: var(--green);
    border: 1px solid #1a3a28;
    display: flex;
    align-items: center;
    gap: 5px;
  }
  .badge-wss .dot {
    width: 6px;
    height: 6px;
    border-radius: 50%;
    background: var(--text-dim);
    transition: background 0.3s;
  }
  .badge-wss.live .dot {
    background: var(--green);
    box-shadow: 0 0 6px rgba(74,222,128,0.5);
    animation: pulse-dot 2s ease-in-out infinite;
  }
  @keyframes pulse-dot {
    0%, 100% { box-shadow: 0 0 4px rgba(74,222,128,0.3); }
    50% { box-shadow: 0 0 10px rgba(74,222,128,0.6); }
  }
  .fallback-banner {
    display: none;
    background: var(--red-dim);
    border-bottom: 1px solid #4a1515;
    color: var(--red);
    font-size: 11px;
    font-weight: 500;
    padding: 6px 16px;
    text-align: center;
    letter-spacing: 0.3px;
  }
  .fallback-banner.active { display: block; }
  .badge-fallback {
    display: none;
    background: var(--red-dim);
    color: var(--red);
    border: 1px solid #4a1515;
    animation: pulse-warn 1.5s ease-in-out infinite;
  }
  .badge-fallback.active { display: inline-block; }
  @keyframes pulse-warn {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.5; }
  }

  .header-right {
    display: flex;
    align-items: center;
    gap: 8px;
  }

  .btn-sm {
    font-family: var(--mono);
    font-size: 9px;
    font-weight: 500;
    padding: 4px 10px;
    background: none;
    border: 1px solid var(--border);
    color: var(--text-muted);
    border-radius: 3px;
    cursor: pointer;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    transition: all 0.15s;
  }
  .btn-sm:hover { border-color: var(--border-warm); color: var(--amber); }

  /* ‚îÄ‚îÄ Config panel ‚îÄ‚îÄ */
  .config {
    background: var(--bg-deep);
    border-bottom: 1px solid var(--border);
    max-height: 0;
    overflow: hidden;
    transition: max-height 0.35s ease, padding 0.35s ease;
    padding: 0 24px;
  }
  .config.open { max-height: 160px; padding: 14px 24px; }

  .config-row {
    display: flex;
    align-items: center;
    gap: 10px;
  }
  .config-row label {
    font-size: 10px;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.5px;
    min-width: 60px;
  }
  .config-input {
    flex: 1;
    background: var(--bg-void);
    border: 1px solid var(--border);
    color: var(--text);
    padding: 7px 12px;
    border-radius: 3px;
    font-family: var(--mono);
    font-size: 11px;
    outline: none;
    transition: border-color 0.2s;
  }
  .config-input:focus { border-color: var(--border-warm); }
  .config-input::placeholder { color: var(--text-dim); }

  .config-warn {
    font-size: 9px;
    color: var(--text-dim);
    margin-top: 6px;
    line-height: 1.5;
  }

  /* ‚îÄ‚îÄ Main content ‚îÄ‚îÄ */
  .main {
    display: grid;
    grid-template-rows: auto 1fr;
    overflow: hidden;
    padding: 0 24px;
  }

  /* ‚îÄ‚îÄ Scope / Waveform ‚îÄ‚îÄ */
  .scope-container {
    position: relative;
    padding: 20px 0 12px;
    animation: scopeFadeIn 0.8s ease-out 0.2s both;
  }
  @keyframes scopeFadeIn {
    from { opacity: 0; transform: scale(0.98); }
    to { opacity: 1; transform: scale(1); }
  }

  .scope-frame {
    position: relative;
    border: 1px solid var(--border-warm);
    border-radius: 6px;
    overflow: hidden;
    background: var(--bg-void);
    box-shadow:
      inset 0 0 60px rgba(0,0,0,0.5),
      0 0 30px rgba(212,160,70,0.03);
    transition: box-shadow 0.5s;
  }
  .scope-frame.active {
    box-shadow:
      inset 0 0 60px rgba(0,0,0,0.3),
      0 0 40px rgba(212,160,70,0.08),
      0 0 80px rgba(212,160,70,0.03);
    border-color: var(--border-active);
  }

  .scope-label {
    position: absolute;
    top: 8px;
    left: 12px;
    font-size: 9px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 1.5px;
    z-index: 2;
    user-select: none;
  }
  .scope-label-right {
    position: absolute;
    top: 8px;
    right: 12px;
    font-size: 9px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 0.5px;
    z-index: 2;
    user-select: none;
  }

  #waveform {
    width: 100%;
    height: 180px;
    display: block;
  }

  /* ‚îÄ‚îÄ Scope VU meter ‚îÄ‚îÄ */
  .vu-strip {
    display: flex;
    align-items: center;
    gap: 6px;
    padding: 6px 12px;
    border-top: 1px solid var(--border);
    background: rgba(0,0,0,0.3);
  }
  .vu-label {
    font-size: 8px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 1px;
    min-width: 28px;
  }
  .vu-track {
    flex: 1;
    height: 3px;
    background: var(--bg-surface);
    border-radius: 2px;
    overflow: hidden;
  }
  .vu-fill {
    height: 100%;
    width: 0%;
    background: linear-gradient(90deg, var(--amber) 0%, var(--amber-hot) 80%, var(--red) 100%);
    border-radius: 2px;
    transition: width 0.1s ease-out;
  }
  .vu-db {
    font-size: 8px;
    color: var(--text-dim);
    min-width: 36px;
    text-align: right;
    font-variant-numeric: tabular-nums;
  }

  /* ‚îÄ‚îÄ Event log ‚îÄ‚îÄ */
  .log-panel {
    display: flex;
    flex-direction: column;
    overflow: hidden;
    border: 1px solid var(--border);
    border-radius: 4px;
    margin-bottom: 0;
    background: var(--bg-deep);
    animation: logFadeIn 0.8s ease-out 0.4s both;
  }
  @keyframes logFadeIn {
    from { opacity: 0; transform: translateY(6px); }
    to { opacity: 1; transform: translateY(0); }
  }

  .log-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 8px 12px;
    border-bottom: 1px solid var(--border);
    flex-shrink: 0;
  }
  .log-title {
    font-size: 9px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 1.2px;
  }
  .log-clear {
    font-size: 8px;
    color: var(--text-dim);
    cursor: pointer;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    border: none;
    background: none;
    font-family: var(--mono);
    padding: 2px 6px;
    border-radius: 2px;
    transition: color 0.15s;
  }
  .log-clear:hover { color: var(--text-muted); }

  .log-entries {
    flex: 1;
    overflow-y: auto;
    padding: 4px 0;
    min-height: 80px;
    max-height: 200px;
  }
  .log-entries::-webkit-scrollbar { width: 4px; }
  .log-entries::-webkit-scrollbar-thumb { background: var(--border); border-radius: 2px; }

  .log-entry {
    display: flex;
    align-items: flex-start;
    gap: 8px;
    padding: 3px 12px;
    font-size: 11px;
    line-height: 1.5;
    animation: logSlide 0.15s ease-out;
  }
  @keyframes logSlide {
    from { opacity: 0; transform: translateX(-4px); }
    to { opacity: 1; transform: translateX(0); }
  }

  .log-time {
    color: var(--text-dim);
    font-size: 9px;
    flex-shrink: 0;
    min-width: 56px;
    font-variant-numeric: tabular-nums;
    padding-top: 1px;
  }
  .log-dot {
    width: 5px;
    height: 5px;
    border-radius: 50%;
    flex-shrink: 0;
    margin-top: 5px;
  }
  .log-dot.ok { background: var(--green); }
  .log-dot.warn { background: var(--amber); }
  .log-dot.err { background: var(--red); }
  .log-dot.audio { background: var(--amber); box-shadow: 0 0 4px rgba(212,160,70,0.4); }
  .log-dot.info { background: var(--text-dim); }

  .log-text { color: var(--text-muted); }
  .log-text .hl { color: var(--amber); }
  .log-text .val { color: var(--text); }

  /* ‚îÄ‚îÄ Input area ‚îÄ‚îÄ */
  .input-area {
    padding: 14px 24px;
    border-top: 1px solid var(--border);
    background: linear-gradient(180deg, transparent 0%, rgba(212,160,70,0.02) 100%);
    animation: inputReveal 0.6s ease-out 0.3s both;
  }
  @keyframes inputReveal {
    from { opacity: 0; transform: translateY(8px); }
    to { opacity: 1; transform: translateY(0); }
  }

  .input-row {
    display: flex;
    gap: 8px;
    align-items: center;
  }

  .mic-btn {
    width: 40px; height: 40px;
    border-radius: 50%;
    border: 2px solid var(--border);
    background: var(--bg-raised);
    color: var(--text-muted);
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 16px;
    transition: all 0.2s;
    flex-shrink: 0;
  }
  .mic-btn:hover { border-color: var(--border-warm); color: var(--amber); }
  .mic-btn.active {
    border-color: var(--red);
    background: var(--red-dim);
    color: var(--red);
    animation: micPulse 1.5s ease-in-out infinite;
  }
  @keyframes micPulse {
    0%, 100% { box-shadow: 0 0 0 0 rgba(239,68,68,0.3); }
    50% { box-shadow: 0 0 0 8px rgba(239,68,68,0); }
  }

  .config-select {
    flex: 1;
    background: var(--bg-void);
    border: 1px solid var(--border);
    color: var(--text);
    padding: 7px 12px;
    border-radius: 3px;
    font-family: var(--mono);
    font-size: 11px;
    outline: none;
    transition: border-color 0.2s;
  }
  .config-select:focus { border-color: var(--border-warm); }

  .text-input {
    flex: 1;
    background: var(--bg-deep);
    border: 1px solid var(--border);
    color: var(--text);
    padding: 10px 14px;
    border-radius: 4px;
    font-family: var(--mono);
    font-size: 12px;
    outline: none;
    transition: border-color 0.2s, box-shadow 0.2s;
  }
  .text-input:focus {
    border-color: var(--border-warm);
    box-shadow: 0 0 0 2px var(--amber-dim);
  }
  .text-input::placeholder { color: var(--text-dim); }
  .text-input:disabled { opacity: 0.4; cursor: not-allowed; }

  .send-btn {
    padding: 10px 20px;
    background: linear-gradient(135deg, var(--amber) 0%, #c89038 100%);
    color: var(--bg-void);
    border: none;
    border-radius: 4px;
    font-family: var(--mono);
    font-size: 10px;
    font-weight: 700;
    cursor: pointer;
    text-transform: uppercase;
    letter-spacing: 1px;
    transition: all 0.2s;
    box-shadow: 0 2px 8px rgba(212,160,70,0.2);
  }
  .send-btn:hover {
    background: linear-gradient(135deg, var(--amber-bright) 0%, var(--amber) 100%);
    box-shadow: 0 4px 16px rgba(212,160,70,0.3);
    transform: translateY(-1px);
  }
  .send-btn:active { transform: translateY(0); }
  .send-btn:disabled {
    background: var(--bg-surface);
    color: var(--text-dim);
    cursor: not-allowed;
    box-shadow: none;
    transform: none;
  }

  /* ‚îÄ‚îÄ Stats bar ‚îÄ‚îÄ */
  .stats-bar {
    display: flex;
    align-items: center;
    gap: 20px;
    padding: 8px 24px;
    border-top: 1px solid var(--border);
    background: var(--bg-deep);
    animation: statsReveal 0.6s ease-out 0.5s both;
  }
  @keyframes statsReveal {
    from { opacity: 0; }
    to { opacity: 1; }
  }

  .stat {
    display: flex;
    align-items: center;
    gap: 6px;
    font-size: 9px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 0.5px;
  }
  .stat-val {
    color: var(--text-muted);
    font-variant-numeric: tabular-nums;
    min-width: 24px;
  }
  .stat-val.active { color: var(--amber); }
  .stat-sep {
    width: 1px;
    height: 10px;
    background: var(--border);
  }

  /* ‚îÄ‚îÄ Idle animation on scope ‚îÄ‚îÄ */
  .scope-idle-text {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    font-family: var(--display);
    font-size: 13px;
    font-weight: 300;
    color: var(--text-dim);
    letter-spacing: 2px;
    text-transform: uppercase;
    z-index: 2;
    pointer-events: none;
    transition: opacity 0.5s;
  }
  .scope-idle-text.hidden { opacity: 0; }

  /* ‚îÄ‚îÄ Responsive ‚îÄ‚îÄ */
  @media (max-width: 700px) {
    .app { max-width: 100%; }
    .header { padding: 10px 14px; }
    .main { padding: 0 14px; }
    .input-area { padding: 10px 14px; }
    .stats-bar { padding: 6px 14px; gap: 12px; flex-wrap: wrap; }
    .badge-model { display: none; }
    #waveform { height: 140px; }
  }
</style>
<script src="../../wasm/wasm_exec.js"></script>
<script src="../../wasm/ailang-repl.js"></script>
</head>
<body>

<div class="app">
  <!-- ‚îÄ‚îÄ Header ‚îÄ‚îÄ -->
  <div class="header">
    <div class="header-left">
      <div class="logo">AILANG<span>√ó</span>Gemini Live</div>
      <span class="badge badge-model">gemini-2.5-flash-native-audio</span>
      <span class="badge badge-wss" id="wssBadge"><span class="dot"></span>WSS</span>
      <span class="badge badge-fallback" id="fallbackBadge">FALLBACK</span>
    </div>
    <div class="header-right">
      <button class="btn-sm" onclick="toggleConfig()" id="cfgBtn">Config</button>
      <button class="btn-sm" onclick="reconnect()" id="reconnBtn">Connect</button>
    </div>
  </div>
  <div class="fallback-banner" id="fallbackBanner">AILANG closure failed ‚Äî running in JS fallback mode (ApplyClosure bug). Events processed via AILANG pure functions, not std/stream closure.</div>

  <!-- ‚îÄ‚îÄ Config ‚îÄ‚îÄ -->
  <div class="config" id="configPanel">
    <div class="config-row">
      <label>API Key</label>
      <input type="password" class="config-input" id="apiKey"
             placeholder="Gemini API key (AI Studio)"
             value="">
    </div>
    <div class="config-row" style="margin-top:8px">
      <label>Voice</label>
      <select class="config-select" id="voiceSelect" onchange="saveConfig()">
        <option value="Sulafat">Sulafat (Warm)</option>
        <option value="Zephyr">Zephyr (Bright)</option>
        <option value="Puck">Puck (Upbeat)</option>
        <option value="Charon">Charon (Informative)</option>
        <option value="Kore">Kore (Firm)</option>
        <option value="Fenrir">Fenrir (Excitable)</option>
        <option value="Leda">Leda (Youthful)</option>
        <option value="Orus">Orus (Firm)</option>
        <option value="Aoede">Aoede (Breezy)</option>
        <option value="Callirrhoe">Callirrhoe (Easy-going)</option>
        <option value="Autonoe">Autonoe (Bright)</option>
        <option value="Enceladus">Enceladus (Breathy)</option>
        <option value="Iapetus">Iapetus (Clear)</option>
        <option value="Umbriel">Umbriel (Easy-going)</option>
        <option value="Algieba">Algieba (Smooth)</option>
        <option value="Despina">Despina (Smooth)</option>
        <option value="Erinome">Erinome (Clear)</option>
        <option value="Algenib">Algenib (Gravelly)</option>
        <option value="Rasalgethi">Rasalgethi (Informative)</option>
        <option value="Laomedeia">Laomedeia (Upbeat)</option>
        <option value="Achernar">Achernar (Soft)</option>
        <option value="Alnilam">Alnilam (Firm)</option>
        <option value="Schedar">Schedar (Even)</option>
        <option value="Gacrux">Gacrux (Mature)</option>
        <option value="Pulcherrima">Pulcherrima (Forward)</option>
        <option value="Achird">Achird (Friendly)</option>
        <option value="Zubenelgenubi">Zubenelgenubi (Casual)</option>
        <option value="Vindemiatrix">Vindemiatrix (Gentle)</option>
        <option value="Sadachbia">Sadachbia (Lively)</option>
        <option value="Sadaltager">Sadaltager (Knowledgeable)</option>
      </select>
    </div>
    <div class="config-warn">
      API calls go directly from your browser to Google's API. Key is stored in localStorage.
    </div>
  </div>

  <!-- ‚îÄ‚îÄ Main ‚îÄ‚îÄ -->
  <div class="main">
    <!-- Oscilloscope / Waveform -->
    <div class="scope-container">
      <div class="scope-frame" id="scopeFrame">
        <span class="scope-label">Audio Scope</span>
        <span class="scope-label-right" id="scopeRate"><span style="color:var(--amber)">output</span> ¬∑ <span style="color:#38bdf8">mic</span> ¬∑ <span style="color:var(--green)">arrival</span></span>
        <span class="scope-idle-text" id="scopeIdle">awaiting signal</span>
        <canvas id="waveform"></canvas>
        <div class="vu-strip">
          <span class="vu-label">VU</span>
          <div class="vu-track"><div class="vu-fill" id="vuFill"></div></div>
          <span class="vu-db" id="vuDb">-‚àû dB</span>
        </div>
      </div>
    </div>

    <!-- Event log -->
    <div class="log-panel">
      <div class="log-header">
        <span class="log-title">Event Log</span>
        <button class="log-clear" onclick="clearLog()">Clear</button>
      </div>
      <div class="log-entries" id="logEntries"></div>
    </div>
  </div>

  <!-- ‚îÄ‚îÄ Input ‚îÄ‚îÄ -->
  <div class="input-area">
    <div class="input-row">
      <button class="mic-btn" id="micBtn" onclick="toggleMic()" title="Toggle microphone">üé§</button>
      <input type="text" class="text-input" id="textInput"
             placeholder="Type or speak to Gemini..."
             disabled>
      <button class="send-btn" id="sendBtn" onclick="sendText()" disabled>Send</button>
    </div>
  </div>

  <!-- ‚îÄ‚îÄ Stats ‚îÄ‚îÄ -->
  <div class="stats-bar">
    <div class="stat">
      <span>State</span>
      <span class="stat-val" id="fState">idle</span>
    </div>
    <div class="stat-sep"></div>
    <div class="stat">
      <span>Frames</span>
      <span class="stat-val" id="fFrames">0</span>
    </div>
    <div class="stat-sep"></div>
    <div class="stat">
      <span>Audio</span>
      <span class="stat-val" id="fBytes">0 B</span>
    </div>
    <div class="stat-sep"></div>
    <div class="stat">
      <span>Duration</span>
      <span class="stat-val" id="fDuration">0.0s</span>
    </div>
    <div class="stat-sep"></div>
    <div class="stat">
      <span>Latency</span>
      <span class="stat-val" id="fLatency">‚Äî</span>
    </div>
  </div>
</div>

<script>
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// Gemini Live ‚Äî AILANG WASM Streaming Demo
//
// Architecture: AILANG drives the full session lifecycle via std/stream effects.
// JS registers effect handlers that bridge Stream ops to browser WebSocket API.
// AILANG controls: connect ‚Üí setup ‚Üí event loop ‚Üí disconnect.
// JS provides: WebSocket transport, audio playback, mic capture, UI rendering.
//
// This is the same streaming model as the CLI (main.ail) ‚Äî AILANG controls
// the session. JS just provides browser APIs via effect handlers.
//
// Template: use this as a starting point for new AILANG streaming audio demos.
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

// ‚îÄ‚îÄ Configuration ‚îÄ‚îÄ
const CONFIG = {
  wasmModule: 'streaming/gemini_live/gemini_live_browser',
  playbackRate: 48000,     // AudioContext output rate (browser standard)
  sourceRate: 24000,       // Gemini audio output rate
  micRate: 16000,          // Mic capture rate (Gemini input)
  fftSize: 2048,           // AnalyserNode FFT size for waveform
  canvasHeight: 180,       // Scope canvas height in CSS pixels
  systemInstruction: 'You are a friendly, expressive assistant called AILANG. Speak with a British English accent. Keep responses short and conversational.',
  initialPrompt: 'Hello!',
  localStorageKeys: {
    apiKey: 'gemini-api-key',
    legacyApiKey: 'gemini_live_key',  // migration from old key name
    voice: 'gemini-live-voice',
  },
};

// ‚îÄ‚îÄ State ‚îÄ‚îÄ
let audioCtx = null;
let captureCtx = null;
let playbackNode = null;
let captureNode = null;
let isRecording = false;
let sessionReady = false;
let promptSentAt = 0;
let totalFrames = 0;
let totalBytes = 0;
let totalSamples = 0;
let lastPcmChunk = null;   // copy of latest PCM for VU meter (analyser reads resampled 48kHz)

// AILANG WASM state
let wasmEngine = null;
let wasmReady = false;
let sessionPrompt = '';    // stored for fallback event processing

// ‚îÄ‚îÄ AILANG WASM Initialization ‚îÄ‚îÄ
// Loads the AILANG module and registers effect handlers so AILANG can drive
// the full session lifecycle via std/stream effects.
async function initWASM() {
  if (wasmReady) return;
  try {
    if (typeof AilangREPL === 'undefined') { addLog('warn', 'WASM not available'); return; }
    const repl = new AilangREPL();
    await repl.init('../../wasm/ailang.wasm');

    // Import stdlib modules needed by the AILANG module
    for (const lib of ['std/json', 'std/option', 'std/result', 'std/string', 'std/list', 'std/io', 'std/stream']) {
      repl.importModule(lib);
    }

    // Register Stream effect handlers ‚Äî bridges std/stream ops to browser WebSocket
    registerStreamHandlers(repl);

    // Register IO effect handler ‚Äî captures println for UI events
    registerIOHandler(repl);

    // Load the AILANG Gemini Live module
    const resp = await fetch('../../ailang/streaming/gemini_live/gemini_live_browser.ail?v=' + Date.now());
    if (!resp.ok) throw new Error('Failed to fetch AILANG module');
    const code = await resp.text();
    const result = repl.loadModule(CONFIG.wasmModule, code);
    if (!result.success) throw new Error(result.error);

    // Import module so zero-arg functions work via eval()
    repl.importModule(CONFIG.wasmModule);

    wasmEngine = repl;
    wasmReady = true;
    // Log is shown via addLog below ‚Äî no console.log needed
    addLog('ok', 'AILANG WASM loaded ‚Äî <span class="hl">std/stream effects</span> bridged to browser');

    // Populate voices from AILANG catalog
    populateVoicesFromAILANG();
  } catch (e) {
    logError('WASM init failed', e);
  }
}

// ‚îÄ‚îÄ Stream Effect Handlers ‚îÄ‚îÄ
// Bridges AILANG std/stream operations to browser WebSocket API.
// AILANG calls connect/transmit/onEvent/runEventLoop/disconnect ‚Äî JS implements them.
// Returns proper ADT values via AilangREPL.adt() so AILANG pattern matching works.
const connections = {};  // connId ‚Üí { ws, eventHandler, eventQueue, done }
let nextConnId = 1;

// Extract numeric connId from StreamConn ADT object.
// New WASM converts TaggedValue to {_ctor: "StreamConn", _fields: [id]}.
function extractConnId(arg) {
  if (typeof arg === 'number') return arg;
  if (arg && arg._ctor === 'StreamConn' && arg._fields) return arg._fields[0];
  return arg;
}

function registerStreamHandlers(repl) {
  repl.setEffectHandler('Stream', {
    // connect(url, config) ‚Üí Result[StreamConn, StreamErrorKind]
    connect: (url, config) => {
      return new Promise((resolve) => {
        const connId = nextConnId++;
        let settled = false;
        const socket = new WebSocket(url);
        // Use arraybuffer to avoid async Blob‚Üítext conversion (eliminates micro-delays)
        socket.binaryType = 'arraybuffer';
        connections[connId] = {
          ws: socket, eventHandler: null, eventQueue: [], resolveRecv: null, done: false
        };
        const decoder = new TextDecoder();

        socket.onopen = () => {
          connections[connId].eventQueue.push({ type: 'Opened', data: url });
          if (connections[connId].resolveRecv) {
            connections[connId].resolveRecv(connections[connId].eventQueue.shift());
            connections[connId].resolveRecv = null;
          }
          $.wssBadge.classList.add('live');
          if (!settled) {
            settled = true;
            resolve(AilangREPL.streamOk(AilangREPL.streamConn(connId)));
          }
        };

        socket.onmessage = (e) => {
          // Synchronous ‚Äî no async gaps between frames
          const text = typeof e.data === 'string' ? e.data : decoder.decode(e.data);
          const conn = connections[connId];
          if (!conn) return;
          conn.eventQueue.push({ type: 'Binary', data: text });
          if (conn.resolveRecv) {
            conn.resolveRecv(conn.eventQueue.shift());
            conn.resolveRecv = null;
          }
        };

        socket.onclose = (e) => {
          const conn = connections[connId];
          if (!conn) return;
          conn.eventQueue.push({ type: 'Closed', code: e.code, reason: e.reason || '' });
          conn.done = true;
          if (conn.resolveRecv) {
            conn.resolveRecv(conn.eventQueue.shift());
            conn.resolveRecv = null;
          }
          $.wssBadge.classList.remove('live');
          if (!settled) {
            settled = true;
            resolve(AilangREPL.streamErr('ConnectionFailed', 'closed: ' + (e.reason || e.code)));
          }
        };

        socket.onerror = () => {
          const conn = connections[connId];
          if (conn && !conn.done) {
            conn.eventQueue.push({ type: 'Closed', code: 1006, reason: 'WebSocket error' });
            conn.done = true;
            if (conn.resolveRecv) {
              conn.resolveRecv(conn.eventQueue.shift());
              conn.resolveRecv = null;
            }
          }
          if (!settled) {
            settled = true;
            resolve(AilangREPL.streamErr('ConnectionFailed', 'WebSocket error'));
          }
        };
      });
    },

    // send(conn, msg) ‚Üí Result[(), StreamErrorKind]
    send: (connArg, msg) => {
      const connId = extractConnId(connArg);
      const conn = connections[connId];
      if (!conn || !conn.ws || conn.ws.readyState !== 1)
        return AilangREPL.streamErr('SendFailed', 'not connected');
      conn.ws.send(typeof msg === 'string' ? msg : msg);
      return AilangREPL.streamOk(null);
    },

    // onEvent(conn, handler) ‚Üí ()
    // Stores the AILANG closure (now a callable js.FuncOf thanks to Phase 1 fix).
    onEvent: (connArg, handler) => {
      const connId = extractConnId(connArg);
      const conn = connections[connId];
      if (conn) conn.eventHandler = handler;
    },

    // runEventLoop(conn) ‚Üí ()
    // Reads events, constructs StreamEvent ADTs, calls AILANG handler.
    // Falls back to JS-side processing with AILANG pure functions if
    // the closure returns nil (ApplyClosure bug ‚Äî reported to AILANG core).
    //
    // Audio optimization: drains queued events in a tight loop (no setTimeout
    // between frames) to avoid 4ms+ minimum delay that starves the audio buffer.
    // Only yields when the queue is empty (await naturally pauses until next event).
    runEventLoop: (connArg) => {
      const connId = extractConnId(connArg);
      return new Promise((resolve) => {
        const conn = connections[connId];
        if (!conn) { resolve(); return; }

        async function eventLoop() {
          while (true) {
            if (!connections[connId]) { resolve(); return; }

            // Drain all queued events in a tight loop, then await next
            let event;
            if (conn.eventQueue.length > 0) {
              event = conn.eventQueue.shift();
            } else if (conn.done) {
              resolve(); return;
            } else {
              // Queue empty ‚Äî await yields to browser naturally
              event = await new Promise(r => { conn.resolveRecv = r; });
            }
            if (!event) { resolve(); return; }

            let keepGoing = true;

            if (conn.eventHandler) {
              // Ideal path: call AILANG closure with StreamEvent ADT
              let streamEvent;
              switch (event.type) {
                case 'Message': streamEvent = AilangREPL.adt('Message', event.data); break;
                case 'Binary':  streamEvent = AilangREPL.adt('Binary', event.data); break;
                case 'Opened':  streamEvent = AilangREPL.adt('Opened', event.data || ''); break;
                case 'Closed':  streamEvent = AilangREPL.adt('Closed', event.code || 0, event.reason || ''); break;
                case 'StreamError': streamEvent = AilangREPL.adt('StreamError', event.data || ''); break;
                case 'Ping':    streamEvent = AilangREPL.adt('Ping', event.data || ''); break;
                default:        streamEvent = AilangREPL.adt('StreamError', 'unknown event'); break;
              }

              try {
                const result = conn.eventHandler(streamEvent);
                if (result === undefined || result === null) {
                  // ApplyClosure bug ‚Äî closure can't resolve cross-module imports
                  conn.eventHandler = null;
                  activateFallbackMode('Closure returned nil ‚Äî cross-module imports not resolved');
                  keepGoing = processEventFallback(event, conn);
                } else {
                  keepGoing = result;
                }
              } catch (e) {
                // Event handler threw ‚Äî fall back to pure functions
                conn.eventHandler = null;
                activateFallbackMode('Closure error: ' + e.message);
                keepGoing = processEventFallback(event, conn);
              }
            } else {
              keepGoing = processEventFallback(event, conn);
            }

            if (!keepGoing || conn.done) { resolve(); return; }
            // Loop continues immediately ‚Äî no setTimeout delay
          }
        }

        eventLoop();
      });
    },

    // close(conn) ‚Üí ()
    close: (connArg) => {
      const connId = extractConnId(connArg);
      const conn = connections[connId];
      if (conn && conn.ws) {
        conn.ws.close();
        conn.done = true;
      }
      delete connections[connId];
    },

    // status(conn) ‚Üí string
    status: (connArg) => {
      const connId = extractConnId(connArg);
      const conn = connections[connId];
      if (!conn || !conn.ws) return 'StreamClosed';
      switch (conn.ws.readyState) {
        case 0: return 'Connecting';
        case 1: return 'Open';
        case 2: return 'Closing';
        default: return 'StreamClosed';
      }
    }
  });
}

// ‚îÄ‚îÄ IO Effect Handler ‚îÄ‚îÄ
// Captures AILANG println output for UI event dispatch.
// AILANG's event handler emits JSON events via println which JS intercepts.
function registerIOHandler(repl) {
  repl.setEffectHandler('IO', {
    println: (text) => {
      // AILANG emits JSON event strings via println
      try {
        const event = JSON.parse(text);
        handleAILANGEvent(event);
      } catch {
        // Plain text output ‚Äî show in log
        if (text && text.trim()) addLog('info', escapeHtml(text));
      }
    }
  });
}

// ‚îÄ‚îÄ Fallback mode signal ‚îÄ‚îÄ
// Shows a prominent red banner + pulsing badge when AILANG closures fail.
function activateFallbackMode(reason) {
  $.fallbackBanner.classList.add('active');
  $.fallbackBadge.classList.add('active');
  addLog('err', 'FALLBACK MODE: ' + reason);
  addLog('warn', 'Events processed via JS + AILANG pure functions (not std/stream closure)');
}
function deactivateFallbackMode() {
  $.fallbackBanner.classList.remove('active');
  $.fallbackBadge.classList.remove('active');
}

// ‚îÄ‚îÄ FALLBACK: event processing when AILANG closure is unavailable ‚îÄ‚îÄ
// DEPRECATED: This fallback exists for the ApplyClosure bug (M-WASM-CLOSURE-ENV).
// Now that the bug is fixed, this code should never activate. The red FALLBACK
// banner + badge appear if it does. Remove once confirmed stable across AILANG versions.
//
// Uses AILANG pure functions (parseMessage, buildTextMessage) for protocol logic.
// Audio frames are fast-tracked in JS to avoid WASM FFI overhead per frame.
// AILANG still drives the session lifecycle ‚Äî this only replaces the event handler closure.
function processEventFallback(event, conn) {
  if (event.type === 'Opened') {
    handleAILANGEvent({ type: 'opened' });
    return true;
  }
  if (event.type === 'Closed') {
    handleAILANGEvent({ type: 'closed', code: event.code, reason: event.reason });
    return false;
  }
  if (event.type === 'StreamError') {
    handleAILANGEvent({ type: 'error', text: event.data });
    return false;
  }
  if (event.type === 'Ping') return true;

  // Binary or Message ‚Äî check for audio fast-track before calling WASM
  const text = event.data;
  if (!text) return true;

  try {
    // Fast-track: parse JSON in JS, handle audio frames without WASM round-trip.
    // WASM parseMessage is ~2-5ms per call ‚Äî too slow for rapid audio frames.
    const json = JSON.parse(text);

    if (json.setupComplete) {
      handleAILANGEvent({ type: 'setup' });
      // Send initial prompt via AILANG buildTextMessage (pure function)
      if (sessionPrompt) {
        const textMsg = callAILANG('buildTextMessage', sessionPrompt);
        if (textMsg && conn.ws && conn.ws.readyState === 1) conn.ws.send(textMsg);
        handleAILANGEvent({ type: 'sent', text: sessionPrompt });
      }
      return true;
    }

    if (json.serverContent) {
      const sc = json.serverContent;
      if (sc.turnComplete) {
        handleAILANGEvent({ type: 'turnComplete' });
        return true;
      }
      // Transcriptions
      if (sc.inputTranscription && sc.inputTranscription.text)
        handleAILANGEvent({ type: 'inputTranscript', text: sc.inputTranscription.text });
      if (sc.outputTranscription && sc.outputTranscription.text)
        handleAILANGEvent({ type: 'outputTranscript', text: sc.outputTranscription.text });
      // Audio/text parts ‚Äî fast path, no WASM needed
      if (sc.modelTurn && sc.modelTurn.parts)
        handleAILANGEvent({ type: 'modelTurn', parts: sc.modelTurn.parts });
      return true;
    }

    if (json.toolCall) {
      const calls = json.toolCall.functionCalls || [];
      handleAILANGEvent({ type: 'toolCall', calls });
      return true;
    }

    return true;
  } catch {
    // JSON parse failed ‚Äî try AILANG parseMessage as fallback
    const parsed = callAILANG('parseMessage', text);
    if (!parsed) return true;
    try {
      handleAILANGEvent(JSON.parse(parsed));
    } catch { /* ignore */ }
    return true;
  }
}

// Process JSON events emitted by AILANG's event handler via println
function handleAILANGEvent(event) {
  switch (event.type) {
    case 'log':
      addLog('info', escapeHtml(event.text || ''));
      break;
    case 'setup':
      sessionReady = true;
      setState('ready');
      addLog('ok', '<span class="hl">Setup complete</span> ‚Äî AILANG streaming session active');
      break;
    case 'sent':
      addLog('info', 'Sent: <span class="val">' + escapeHtml(event.text || '') + '</span>');
      setState('streaming');
      promptSentAt = Date.now();
      break;
    case 'turnComplete':
      sessionReady = true;
      setState('ready');
      addLog('ok', '<span class="hl">Turn complete</span> ‚Äî <span class="val">' + totalFrames + '</span> frames, <span class="val">' + fmtBytes(totalBytes) + '</span>');
      $.sendBtn.disabled = false;
      $.textInput.disabled = false;
      $.textInput.focus();
      break;
    case 'inputTranscript':
      if (event.text) addLog('info', 'You said: <span class="val">' + escapeHtml(event.text) + '</span>');
      break;
    case 'outputTranscript':
      if (event.text) addLog('info', 'Model: <span class="val">' + escapeHtml(event.text) + '</span>');
      break;
    case 'modelTurn':
      if (event.parts && Array.isArray(event.parts)) {
        event.parts.forEach(part => {
          if (part.text) addLog('info', 'Transcript: <span class="val">' + escapeHtml(part.text) + '</span>');
          if (part.inlineData && part.inlineData.data) handleAudioFrame(part.inlineData.data);
        });
      }
      break;
    case 'toolCall':
      addLog('warn', 'Tool call: <span class="val">' + JSON.stringify(event.calls || []).substring(0, 120) + '</span>');
      break;
    case 'opened':
      setState('connected');
      addLog('ok', 'WebSocket connected (AILANG Stream effect)');
      break;
    case 'closed':
      sessionReady = false;
      setState('closed');
      addLog('info', 'WebSocket closed <span class="val">' + (event.code || '') + '</span>');
      $.wssBadge.classList.remove('live');
      break;
    case 'error':
      addLog('err', 'AILANG: ' + escapeHtml(event.text || ''));
      break;
  }
}

// Call a pure AILANG function (protocol construction/parsing/config).
// AILANG handles ALL Gemini Live protocol knowledge; JS is just transport.
function callAILANG(funcName, ...args) {
  if (!wasmReady) return null;
  try {
    let val;
    // Always try call() first ‚Äî works for all arities with new WASM binary.
    // Fall back to eval() for zero-arg if call() returns a function object.
    const result = wasmEngine.call(CONFIG.wasmModule, funcName, ...args);
    if (!result.success) { logError('AILANG: ' + result.error); return null; }
    val = result.result || '';
    if (val === '<function>' && args.length === 0) {
      // Zero-arg function returned function object ‚Äî invoke via eval
      val = wasmEngine.eval(funcName + '()');
    }
    val = val.trim();
    // Strip type annotation: "value :: Type" or "value :: Type (desugared)"
    const typeIdx = val.lastIndexOf(' :: ');
    if (typeIdx > 0) val = val.substring(0, typeIdx).trim();
    // Unwrap AILANG string quotes (REPL wraps strings in "...")
    if (val.startsWith('"') && val.endsWith('"')) {
      try { val = JSON.parse(val); } catch { val = val.slice(1, -1); }
    }
    return val;
  } catch (e) {
    logError('AILANG call error', e);
    return null;
  }
}



function populateVoicesFromAILANG() {
  if (!wasmReady) return;
  try {
    const raw = callAILANG('voiceCatalog');
    if (!raw) return;
    const voices = JSON.parse(raw);
    const select = $.voiceSelect;
    const current = select.value;
    select.innerHTML = '';
    voices.forEach(v => {
      const opt = document.createElement('option');
      opt.value = v.name;
      opt.textContent = `${v.name} (${v.desc})`;
      select.appendChild(opt);
    });
    const saved = localStorage.getItem('gemini-live-voice');
    if (saved) select.value = saved;
    else select.value = current || callAILANG('defaultVoice') || 'Sulafat';
  } catch (e) { logError('Voice catalog parse error', e); }
}

// ‚îÄ‚îÄ Cached DOM refs (populated on load) ‚îÄ‚îÄ
const $  = {};
function cacheDom() {
  for (const id of [
    'wssBadge', 'fallbackBanner', 'fallbackBadge', 'configPanel',
    'apiKey', 'voiceSelect', 'logEntries', 'sendBtn', 'textInput',
    'micBtn', 'scopeFrame', 'scopeIdle',
    'fState', 'fFrames', 'fBytes', 'fDuration', 'fLatency',
    'vuFill', 'vuDb',
  ]) {
    $[id] = document.getElementById(id);
  }
}

// ‚îÄ‚îÄ Config ‚îÄ‚îÄ
function toggleConfig() {
  $.configPanel.classList.toggle('open');
}

function loadConfig() {
  const keys = CONFIG.localStorageKeys;
  // Migrate legacy key name
  if (!localStorage.getItem(keys.apiKey) && localStorage.getItem(keys.legacyApiKey))
    localStorage.setItem(keys.apiKey, localStorage.getItem(keys.legacyApiKey));
  const saved = localStorage.getItem(keys.apiKey);
  if (saved) $.apiKey.value = saved;
  const voice = localStorage.getItem(keys.voice);
  if (voice) $.voiceSelect.value = voice;
}

function saveConfig() {
  const key = $.apiKey.value.trim();
  if (key) localStorage.setItem(CONFIG.localStorageKeys.apiKey, key);
  localStorage.setItem(CONFIG.localStorageKeys.voice, $.voiceSelect.value);
}

// ‚îÄ‚îÄ Logging ‚îÄ‚îÄ
function addLog(type, html) {
  const el = document.createElement('div');
  el.className = 'log-entry';
  const now = new Date();
  const ts = String(now.getHours()).padStart(2,'0') + ':' +
             String(now.getMinutes()).padStart(2,'0') + ':' +
             String(now.getSeconds()).padStart(2,'0') + '.' +
             String(now.getMilliseconds()).padStart(3,'0').slice(0,2);
  el.innerHTML = `<span class="log-time">${ts}</span><span class="log-dot ${type}"></span><span class="log-text">${html}</span>`;
  $.logEntries.appendChild(el);
  $.logEntries.scrollTop = $.logEntries.scrollHeight;
}
function logError(msg, err) {
  addLog('err', escapeHtml(msg + (err ? ': ' + err.message : '')));
}
function clearLog() { $.logEntries.innerHTML = ''; }

// ‚îÄ‚îÄ Format helpers ‚îÄ‚îÄ
function fmtBytes(b) {
  if (b < 1024) return b + ' B';
  if (b < 1048576) return (b / 1024).toFixed(1) + ' KB';
  return (b / 1048576).toFixed(2) + ' MB';
}
function updateStats() {
  $.fFrames.textContent = totalFrames;
  $.fBytes.textContent = fmtBytes(totalBytes);
  const dur = totalSamples / CONFIG.sourceRate;
  $.fDuration.textContent = dur.toFixed(1) + 's';
  if (totalFrames > 0) {
    $.fFrames.classList.add('active');
    $.fBytes.classList.add('active');
    $.fDuration.classList.add('active');
  }
}
function setState(s) {
  const el = $.fState;
  el.textContent = s;
  el.classList.toggle('active', s !== 'idle' && s !== 'closed');
}

// ‚îÄ‚îÄ Connect: AILANG drives the full session via std/stream effects ‚îÄ‚îÄ
// AILANG's startSession() calls connect ‚Üí transmit(setup) ‚Üí onEvent ‚Üí runEventLoop ‚Üí disconnect.
// JS effect handlers bridge these to the browser WebSocket API.
async function reconnect() {
  const key = $.apiKey.value.trim() || localStorage.getItem(CONFIG.localStorageKeys.apiKey);
  if (!key) { toggleConfig(); addLog('warn', 'Enter your Gemini API key'); return; }
  saveConfig();

  if (!wasmReady) {
    addLog('err', 'AILANG WASM not loaded ‚Äî cannot start streaming session');
    return;
  }

  sessionReady = false;
  totalFrames = 0; totalBytes = 0; totalSamples = 0;
  updateStats();
  setState('connecting');

  $.sendBtn.disabled = true;
  $.textInput.disabled = true;

  await initAudio();

  const voice = $.voiceSelect.value;
  const instruction = CONFIG.systemInstruction;

  sessionPrompt = CONFIG.initialPrompt;
  deactivateFallbackMode();
  addLog('info', 'Starting AILANG streaming session (std/stream effects)...');

  try {
    // AILANG drives the entire session: connect ‚Üí setup ‚Üí event loop ‚Üí disconnect
    const result = await wasmEngine.callAsync(CONFIG.wasmModule, 'startSession', key, voice, instruction, sessionPrompt);
    if (!result.success) {
      logError('AILANG session: ' + (result.error || 'unknown'));
    } else {
      addLog('info', 'AILANG session ended: <span class="val">' + (result.result || 'complete') + '</span>');
    }
  } catch (e) {
    logError('AILANG session failed', e);
  }

  sessionReady = false;
  setState('closed');
}

// Audio frame processing (browser-specific ‚Äî stays in JS)
// Optimized: efficient base64 decode, deferred DOM updates via rAF.
let _statsRafPending = false;
function handleAudioFrame(b64) {
  if (totalFrames === 0 && promptSentAt > 0) {
    const latency = Date.now() - promptSentAt;
    $.fLatency.textContent = latency + 'ms';
    $.fLatency.classList.add('active');
    addLog('info', 'First audio in <span class="val">' + latency + 'ms</span>');
  }
  totalFrames++;

  // Efficient base64 ‚Üí ArrayBuffer (avoid byte-by-byte charCodeAt loop)
  const binStr = atob(b64);
  const byteLen = binStr.length;
  totalBytes += byteLen;
  const bytes = new Uint8Array(byteLen);
  for (let i = 0; i < byteLen; i++) bytes[i] = binStr.charCodeAt(i);
  const pcm16 = new Int16Array(bytes.buffer);
  const sampleCount = pcm16.length;  // save before buffer transfer
  totalSamples += sampleCount;

  // Save a copy for VU meter + waveform before buffer transfer detaches it
  lastPcmChunk = new Int16Array(pcm16);

  // Feed network arrival envelope for scope visualization
  notifyAudioArrival(sampleCount);

  // Enqueue immediately ‚Äî this is the critical path
  // (postMessage transfers buffer ownership, so pcm16.length becomes 0 after this)
  enqueueAudio(pcm16);

  // Defer VU meter + DOM updates to next animation frame (batch multiple frames)
  if (!_statsRafPending) {
    _statsRafPending = true;
    requestAnimationFrame(() => {
      _statsRafPending = false;
      if (lastPcmChunk) updateVU(lastPcmChunk);
      updateStats();
      $.scopeFrame.classList.add('active');
      $.scopeIdle.classList.add('hidden');
    });
  }

  if (totalFrames <= 3 || totalFrames % 10 === 0) {
    addLog('audio', '<span class="hl">Audio</span> frame <span class="val">#' + totalFrames + '</span> ‚Äî ' + fmtBytes(byteLen) + ' (' + sampleCount + ' samples)');
  }
}

// ‚îÄ‚îÄ Audio playback ‚îÄ‚îÄ
let analyserNode = null;
async function initAudio() {
  if (audioCtx) return;
  audioCtx = new AudioContext({ sampleRate: CONFIG.playbackRate });
  await audioCtx.audioWorklet.addModule('../shared/audio-worklet.js');
  playbackNode = new AudioWorkletNode(audioCtx, 'pcm-playback', {
    processorOptions: { sourceRate: CONFIG.sourceRate }
  });
  // AnalyserNode taps the actual audio output for waveform visualization
  analyserNode = audioCtx.createAnalyser();
  analyserNode.fftSize = CONFIG.fftSize;
  playbackNode.connect(analyserNode);
  analyserNode.connect(audioCtx.destination);
  addLog('ok', 'Audio engine initialized ‚Äî <span class="val">' + CONFIG.sourceRate/1000 + 'kHz ‚Üí ' + CONFIG.playbackRate/1000 + 'kHz</span>');
}
function enqueueAudio(pcm16) {
  if (!playbackNode) return;
  playbackNode.port.postMessage({ type: 'enqueue', pcmData: pcm16.buffer }, [pcm16.buffer]);
}

// ‚îÄ‚îÄ VU meter ‚îÄ‚îÄ
function updateVU(pcm16) {
  let sum = 0;
  for (let i = 0; i < pcm16.length; i++) { const s = pcm16[i] / 32768; sum += s * s; }
  const rms = Math.sqrt(sum / pcm16.length);
  const db = rms > 0 ? 20 * Math.log10(rms) : -60;
  const clamped = Math.max(-60, Math.min(0, db));
  const pct = ((clamped + 60) / 60) * 100;
  $.vuFill.style.width = pct + '%';
  $.vuDb.textContent = db > -60 ? db.toFixed(1) + ' dB' : '-‚àû dB';
}

// ‚îÄ‚îÄ Send text ‚Äî builds message via AILANG, sends through AILANG-managed WebSocket ‚îÄ‚îÄ
async function sendText() {
  const input = $.textInput;
  const text = input.value.trim();
  if (!text || !sessionReady) return;

  // Find the active AILANG-managed WebSocket connection
  const activeConn = Object.values(connections).find(c => c.ws && c.ws.readyState === 1);
  if (!activeConn) { addLog('err', 'No active WebSocket connection'); return; }

  await initAudio();
  totalFrames = 0; totalBytes = 0; totalSamples = 0;
  promptSentAt = Date.now();
  $.fLatency.textContent = '‚Äî';
  $.fLatency.classList.remove('active');
  updateStats();
  if (playbackNode) playbackNode.port.postMessage({ command: 'clear' });

  addLog('info', 'Sending: <span class="val">' + escapeHtml(text) + '</span>');

  // Build message via AILANG WASM, send through the AILANG-managed WebSocket
  const msgJson = callAILANG('buildTextMessage', text);
  activeConn.ws.send(msgJson || JSON.stringify({
    clientContent: { turns: [{ role: 'user', parts: [{ text }] }], turnComplete: true }
  }));

  input.value = '';
  input.disabled = true;
  $.sendBtn.disabled = true;
  setState('streaming');
  $.scopeIdle.textContent = 'receiving audio';
  $.scopeIdle.classList.remove('hidden');
  setTimeout(() => $.scopeIdle.classList.add('hidden'), 1500);
}

function escapeHtml(s) {
  const d = document.createElement('div');
  d.textContent = s;
  return d.innerHTML;
}

// ‚îÄ‚îÄ Microphone capture ‚îÄ‚îÄ
let micAnalyserNode = null;
async function toggleMic() {
  const btn = $.micBtn;
  if (isRecording) {
    isRecording = false;
    btn.classList.remove('active');
    if (captureNode) captureNode.port.postMessage({ command: 'stop' });
    addLog('info', 'Mic stopped');
    return;
  }
  await initAudio();
  if (!captureCtx) {
    captureCtx = new AudioContext();
    await captureCtx.audioWorklet.addModule('../shared/audio-worklet.js');
  }
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const source = captureCtx.createMediaStreamSource(stream);
    // AnalyserNode on mic input for waveform visualization
    micAnalyserNode = captureCtx.createAnalyser();
    micAnalyserNode.fftSize = CONFIG.fftSize;
    source.connect(micAnalyserNode);
    captureNode = new AudioWorkletNode(captureCtx, 'pcm-capture', {
      processorOptions: { targetRate: CONFIG.micRate }
    });
    source.connect(captureNode);
    captureNode.port.onmessage = (e) => {
      const activeConn = Object.values(connections).find(c => c.ws && c.ws.readyState === 1);
      if (e.data.type === 'pcm-chunk' && activeConn && sessionReady) {
        const bytes = new Uint8Array(e.data.pcmData);
        let b = '';
        for (let i = 0; i < bytes.length; i++) b += String.fromCharCode(bytes[i]);
        const b64 = btoa(b);
        // Build audio chunk via AILANG WASM, send via AILANG-managed WebSocket
        const chunkJson = callAILANG('buildAudioChunk', b64);
        activeConn.ws.send(chunkJson || JSON.stringify({
          realtimeInput: { mediaChunks: [{ mimeType: 'audio/pcm;rate=16000', data: b64 }] }
        }));
      }
    };
    isRecording = true;
    btn.classList.add('active');
    addLog('ok', 'Mic active ‚Äî streaming audio at ' + CONFIG.micRate/1000 + 'kHz');
    if (!Object.values(connections).find(c => c.ws && c.ws.readyState === 1)) reconnect();
  } catch (e) {
    addLog('err', 'Mic access denied: ' + e.message);
  }
}

// ‚îÄ‚îÄ Waveform visualization ‚îÄ‚îÄ
// Triple-trace scope: playback output (amber), mic input (cyan), network arrival (green).
const canvas = document.getElementById('waveform');
const ctx = canvas.getContext('2d');
let animId = null;
// Network arrival: rolling RMS envelope (decays between frames)
let arrivalEnvelope = 0;

function resizeCanvas() {
  const rect = canvas.parentElement.getBoundingClientRect();
  const dpr = window.devicePixelRatio || 1;
  canvas.width = rect.width * dpr;
  canvas.height = CONFIG.canvasHeight * dpr;
  canvas.style.height = CONFIG.canvasHeight + 'px';
  ctx.setTransform(dpr, 0, 0, dpr, 0, 0);
}

function drawGrid() {
  const w = canvas.width / (window.devicePixelRatio || 1);
  const h = CONFIG.canvasHeight;
  ctx.strokeStyle = 'rgba(212,160,70,0.04)';
  ctx.lineWidth = 0.5;
  for (let i = 1; i < 6; i++) {
    const y = (h / 6) * i;
    ctx.beginPath(); ctx.moveTo(0, y); ctx.lineTo(w, y); ctx.stroke();
  }
  const cols = Math.floor(w / 40);
  for (let i = 1; i < cols; i++) {
    const x = (w / cols) * i;
    ctx.beginPath(); ctx.moveTo(x, 0); ctx.lineTo(x, h); ctx.stroke();
  }
  ctx.strokeStyle = 'rgba(212,160,70,0.08)';
  ctx.lineWidth = 1;
  ctx.beginPath(); ctx.moveTo(0, h / 2); ctx.lineTo(w, h / 2); ctx.stroke();
}

// Draw a single waveform trace
function drawTrace(waveData, w, h, mid, color, glowColor, lineWidth) {
  // Glow
  ctx.shadowColor = glowColor;
  ctx.shadowBlur = 6;
  ctx.strokeStyle = glowColor;
  ctx.lineWidth = lineWidth + 1.5;
  ctx.beginPath();
  for (let i = 0; i < w; i++) {
    const idx = Math.floor((i / w) * waveData.length);
    const y = mid + waveData[idx] * mid * 0.85;
    if (i === 0) ctx.moveTo(i, y); else ctx.lineTo(i, y);
  }
  ctx.stroke();
  // Main line
  ctx.shadowColor = 'transparent';
  ctx.shadowBlur = 0;
  ctx.strokeStyle = color;
  ctx.lineWidth = lineWidth;
  ctx.beginPath();
  for (let i = 0; i < w; i++) {
    const idx = Math.floor((i / w) * waveData.length);
    const y = mid + waveData[idx] * mid * 0.85;
    if (i === 0) ctx.moveTo(i, y); else ctx.lineTo(i, y);
  }
  ctx.stroke();
}

function drawWaveform() {
  const w = canvas.width / (window.devicePixelRatio || 1);
  const h = CONFIG.canvasHeight;
  const mid = h / 2;

  ctx.clearRect(0, 0, w, h);
  drawGrid();

  // 1. Network arrival envelope ‚Äî green bar along bottom edge
  arrivalEnvelope *= 0.92;  // decay
  if (arrivalEnvelope > 0.01) {
    const barH = Math.min(arrivalEnvelope * 40, 8);
    ctx.fillStyle = 'rgba(74,222,128,' + Math.min(arrivalEnvelope * 2, 0.5) + ')';
    ctx.fillRect(0, h - barH, w, barH);
    ctx.fillStyle = 'rgba(74,222,128,0.08)';
    ctx.fillRect(0, h - barH - 2, w, 2);
  }

  // 2. Playback output ‚Äî amber (primary trace)
  if (analyserNode) {
    const playData = new Float32Array(analyserNode.fftSize);
    analyserNode.getFloatTimeDomainData(playData);
    drawTrace(playData, w, h, mid,
      'rgba(212,160,70,0.7)', 'rgba(212,160,70,0.25)', 1.5);
  }

  // 3. Mic input ‚Äî cyan (when recording)
  if (micAnalyserNode && isRecording) {
    const micData = new Float32Array(micAnalyserNode.fftSize);
    micAnalyserNode.getFloatTimeDomainData(micData);
    drawTrace(micData, w, h, mid,
      'rgba(56,189,248,0.5)', 'rgba(56,189,248,0.15)', 1);
  }

  animId = requestAnimationFrame(drawWaveform);
}

// Called when audio frames arrive from network ‚Äî feeds the arrival envelope
function notifyAudioArrival(sampleCount) {
  arrivalEnvelope = Math.min(arrivalEnvelope + (sampleCount / 2400), 1.0);
}

// ‚îÄ‚îÄ Keyboard ‚îÄ‚îÄ
$.textInput.addEventListener('keydown', (e) => {
  if (e.key === 'Enter' && !e.shiftKey) {
    e.preventDefault();
    sendText();
  }
});

// ‚îÄ‚îÄ Init ‚îÄ‚îÄ
window.addEventListener('load', async () => {
  cacheDom();
  loadConfig();
  resizeCanvas();
  drawWaveform();

  addLog('info', 'AILANG √ó Gemini Live ‚Äî loading WASM streaming engine...');
  await initWASM();
  if (wasmReady) {
    addLog('ok', 'AILANG <span class="hl">std/stream effects</span> bridged to browser WebSocket');
    addLog('info', 'AILANG drives: connect ‚Üí setup ‚Üí event loop ‚Üí disconnect');
  } else {
    addLog('err', 'AILANG WASM failed to load ‚Äî streaming requires AILANG');
  }
  addLog('info', 'Model: <span class="hl">gemini-2.5-flash-native-audio</span>');
  addLog('info', 'Click <span class="val">Connect</span> to start');
});

window.addEventListener('resize', resizeCanvas);
</script>
<script src="../shared/nav.js"></script>
</body>
</html>
