<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AILANG Ã— Gemini Live â€” Text to Audio</title>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400;500;600;700&family=Outfit:wght@300;400;500;600;700&display=swap" rel="stylesheet">
<style>
  :root {
    --bg-void: #050506;
    --bg-deep: #0a0a0c;
    --bg-panel: #0f1012;
    --bg-raised: #151618;
    --bg-surface: #1b1c1f;
    --bg-hover: #222326;
    --border: #1e1f22;
    --border-warm: #2a2520;
    --border-active: #3a3530;
    --text: #c8c4bc;
    --text-muted: #706b62;
    --text-dim: #3d3a35;
    --amber: #d4a046;
    --amber-bright: #e8b85a;
    --amber-hot: #f0c464;
    --amber-glow: rgba(212,160,70,0.12);
    --amber-dim: rgba(212,160,70,0.06);
    --green: #4ade80;
    --green-dim: #0d2818;
    --red: #ef4444;
    --red-dim: #2a0f0f;
    --mono: 'JetBrains Mono', monospace;
    --display: 'Outfit', system-ui, sans-serif;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  html, body {
    height: 100%;
    background: var(--bg-void);
    color: var(--text);
    font-family: var(--mono);
    font-size: 13px;
    overflow: hidden;
    -webkit-font-smoothing: antialiased;
  }

  /* â”€â”€ Noise texture overlay â”€â”€ */
  body::before {
    content: '';
    position: fixed;
    inset: 0;
    z-index: 9999;
    pointer-events: none;
    opacity: 0.025;
    background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 256 256' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='n'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23n)'/%3E%3C/svg%3E");
    background-repeat: repeat;
    background-size: 256px;
  }

  /* â”€â”€ App grid â”€â”€ */
  .app {
    display: grid;
    grid-template-rows: auto auto 1fr auto auto;
    height: 100vh;
    max-width: 1200px;
    margin: 0 auto;
  }

  /* â”€â”€ Header â”€â”€ */
  .header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 14px 24px;
    border-bottom: 1px solid var(--border);
    background: linear-gradient(180deg, rgba(212,160,70,0.03) 0%, transparent 100%);
    animation: headerReveal 0.6s ease-out;
  }
  @keyframes headerReveal {
    from { opacity: 0; transform: translateY(-8px); }
    to { opacity: 1; transform: translateY(0); }
  }

  .header-left {
    display: flex;
    align-items: center;
    gap: 16px;
  }

  .logo {
    font-family: var(--display);
    font-size: 16px;
    font-weight: 600;
    color: var(--amber);
    letter-spacing: -0.3px;
  }
  .logo span {
    color: var(--text-dim);
    font-weight: 300;
    margin: 0 2px;
  }

  .badge {
    font-size: 9px;
    font-weight: 500;
    padding: 3px 8px;
    border-radius: 3px;
    text-transform: uppercase;
    letter-spacing: 0.8px;
  }
  .badge-model {
    background: var(--bg-surface);
    color: var(--text-muted);
    border: 1px solid var(--border);
  }
  .badge-wss {
    background: var(--green-dim);
    color: var(--green);
    border: 1px solid #1a3a28;
    display: flex;
    align-items: center;
    gap: 5px;
  }
  .badge-wss .dot {
    width: 6px;
    height: 6px;
    border-radius: 50%;
    background: var(--text-dim);
    transition: background 0.3s;
  }
  .badge-wss.live .dot {
    background: var(--green);
    box-shadow: 0 0 6px rgba(74,222,128,0.5);
    animation: pulse-dot 2s ease-in-out infinite;
  }
  @keyframes pulse-dot {
    0%, 100% { box-shadow: 0 0 4px rgba(74,222,128,0.3); }
    50% { box-shadow: 0 0 10px rgba(74,222,128,0.6); }
  }

  .header-right {
    display: flex;
    align-items: center;
    gap: 8px;
  }

  .btn-sm {
    font-family: var(--mono);
    font-size: 9px;
    font-weight: 500;
    padding: 4px 10px;
    background: none;
    border: 1px solid var(--border);
    color: var(--text-muted);
    border-radius: 3px;
    cursor: pointer;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    transition: all 0.15s;
  }
  .btn-sm:hover { border-color: var(--border-warm); color: var(--amber); }

  /* â”€â”€ Config panel â”€â”€ */
  .config {
    background: var(--bg-deep);
    border-bottom: 1px solid var(--border);
    max-height: 0;
    overflow: hidden;
    transition: max-height 0.35s ease, padding 0.35s ease;
    padding: 0 24px;
  }
  .config.open { max-height: 160px; padding: 14px 24px; }

  .config-row {
    display: flex;
    align-items: center;
    gap: 10px;
  }
  .config-row label {
    font-size: 10px;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.5px;
    min-width: 60px;
  }
  .config-input {
    flex: 1;
    background: var(--bg-void);
    border: 1px solid var(--border);
    color: var(--text);
    padding: 7px 12px;
    border-radius: 3px;
    font-family: var(--mono);
    font-size: 11px;
    outline: none;
    transition: border-color 0.2s;
  }
  .config-input:focus { border-color: var(--border-warm); }
  .config-input::placeholder { color: var(--text-dim); }

  .config-warn {
    font-size: 9px;
    color: var(--text-dim);
    margin-top: 6px;
    line-height: 1.5;
  }

  /* â”€â”€ Main content â”€â”€ */
  .main {
    display: grid;
    grid-template-rows: auto 1fr;
    overflow: hidden;
    padding: 0 24px;
  }

  /* â”€â”€ Scope / Waveform â”€â”€ */
  .scope-container {
    position: relative;
    padding: 20px 0 12px;
    animation: scopeFadeIn 0.8s ease-out 0.2s both;
  }
  @keyframes scopeFadeIn {
    from { opacity: 0; transform: scale(0.98); }
    to { opacity: 1; transform: scale(1); }
  }

  .scope-frame {
    position: relative;
    border: 1px solid var(--border-warm);
    border-radius: 6px;
    overflow: hidden;
    background: var(--bg-void);
    box-shadow:
      inset 0 0 60px rgba(0,0,0,0.5),
      0 0 30px rgba(212,160,70,0.03);
    transition: box-shadow 0.5s;
  }
  .scope-frame.active {
    box-shadow:
      inset 0 0 60px rgba(0,0,0,0.3),
      0 0 40px rgba(212,160,70,0.08),
      0 0 80px rgba(212,160,70,0.03);
    border-color: var(--border-active);
  }

  .scope-label {
    position: absolute;
    top: 8px;
    left: 12px;
    font-size: 9px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 1.5px;
    z-index: 2;
    user-select: none;
  }
  .scope-label-right {
    position: absolute;
    top: 8px;
    right: 12px;
    font-size: 9px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 0.5px;
    z-index: 2;
    user-select: none;
  }

  #waveform {
    width: 100%;
    height: 180px;
    display: block;
  }

  /* â”€â”€ Scope VU meter â”€â”€ */
  .vu-strip {
    display: flex;
    align-items: center;
    gap: 6px;
    padding: 6px 12px;
    border-top: 1px solid var(--border);
    background: rgba(0,0,0,0.3);
  }
  .vu-label {
    font-size: 8px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 1px;
    min-width: 28px;
  }
  .vu-track {
    flex: 1;
    height: 3px;
    background: var(--bg-surface);
    border-radius: 2px;
    overflow: hidden;
  }
  .vu-fill {
    height: 100%;
    width: 0%;
    background: linear-gradient(90deg, var(--amber) 0%, var(--amber-hot) 80%, var(--red) 100%);
    border-radius: 2px;
    transition: width 0.1s ease-out;
  }
  .vu-db {
    font-size: 8px;
    color: var(--text-dim);
    min-width: 36px;
    text-align: right;
    font-variant-numeric: tabular-nums;
  }

  /* â”€â”€ Event log â”€â”€ */
  .log-panel {
    display: flex;
    flex-direction: column;
    overflow: hidden;
    border: 1px solid var(--border);
    border-radius: 4px;
    margin-bottom: 0;
    background: var(--bg-deep);
    animation: logFadeIn 0.8s ease-out 0.4s both;
  }
  @keyframes logFadeIn {
    from { opacity: 0; transform: translateY(6px); }
    to { opacity: 1; transform: translateY(0); }
  }

  .log-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 8px 12px;
    border-bottom: 1px solid var(--border);
    flex-shrink: 0;
  }
  .log-title {
    font-size: 9px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 1.2px;
  }
  .log-clear {
    font-size: 8px;
    color: var(--text-dim);
    cursor: pointer;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    border: none;
    background: none;
    font-family: var(--mono);
    padding: 2px 6px;
    border-radius: 2px;
    transition: color 0.15s;
  }
  .log-clear:hover { color: var(--text-muted); }

  .log-entries {
    flex: 1;
    overflow-y: auto;
    padding: 4px 0;
    min-height: 80px;
    max-height: 200px;
  }
  .log-entries::-webkit-scrollbar { width: 4px; }
  .log-entries::-webkit-scrollbar-thumb { background: var(--border); border-radius: 2px; }

  .log-entry {
    display: flex;
    align-items: flex-start;
    gap: 8px;
    padding: 3px 12px;
    font-size: 11px;
    line-height: 1.5;
    animation: logSlide 0.15s ease-out;
  }
  @keyframes logSlide {
    from { opacity: 0; transform: translateX(-4px); }
    to { opacity: 1; transform: translateX(0); }
  }

  .log-time {
    color: var(--text-dim);
    font-size: 9px;
    flex-shrink: 0;
    min-width: 56px;
    font-variant-numeric: tabular-nums;
    padding-top: 1px;
  }
  .log-dot {
    width: 5px;
    height: 5px;
    border-radius: 50%;
    flex-shrink: 0;
    margin-top: 5px;
  }
  .log-dot.ok { background: var(--green); }
  .log-dot.warn { background: var(--amber); }
  .log-dot.err { background: var(--red); }
  .log-dot.audio { background: var(--amber); box-shadow: 0 0 4px rgba(212,160,70,0.4); }
  .log-dot.info { background: var(--text-dim); }

  .log-text { color: var(--text-muted); }
  .log-text .hl { color: var(--amber); }
  .log-text .val { color: var(--text); }

  /* â”€â”€ Input area â”€â”€ */
  .input-area {
    padding: 14px 24px;
    border-top: 1px solid var(--border);
    background: linear-gradient(180deg, transparent 0%, rgba(212,160,70,0.02) 100%);
    animation: inputReveal 0.6s ease-out 0.3s both;
  }
  @keyframes inputReveal {
    from { opacity: 0; transform: translateY(8px); }
    to { opacity: 1; transform: translateY(0); }
  }

  .input-row {
    display: flex;
    gap: 8px;
    align-items: center;
  }

  .mic-btn {
    width: 40px; height: 40px;
    border-radius: 50%;
    border: 2px solid var(--border);
    background: var(--bg-raised);
    color: var(--text-muted);
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 16px;
    transition: all 0.2s;
    flex-shrink: 0;
  }
  .mic-btn:hover { border-color: var(--border-warm); color: var(--amber); }
  .mic-btn.active {
    border-color: var(--red);
    background: var(--red-dim);
    color: var(--red);
    animation: micPulse 1.5s ease-in-out infinite;
  }
  @keyframes micPulse {
    0%, 100% { box-shadow: 0 0 0 0 rgba(239,68,68,0.3); }
    50% { box-shadow: 0 0 0 8px rgba(239,68,68,0); }
  }

  .config-select {
    flex: 1;
    background: var(--bg-void);
    border: 1px solid var(--border);
    color: var(--text);
    padding: 7px 12px;
    border-radius: 3px;
    font-family: var(--mono);
    font-size: 11px;
    outline: none;
    transition: border-color 0.2s;
  }
  .config-select:focus { border-color: var(--border-warm); }

  .text-input {
    flex: 1;
    background: var(--bg-deep);
    border: 1px solid var(--border);
    color: var(--text);
    padding: 10px 14px;
    border-radius: 4px;
    font-family: var(--mono);
    font-size: 12px;
    outline: none;
    transition: border-color 0.2s, box-shadow 0.2s;
  }
  .text-input:focus {
    border-color: var(--border-warm);
    box-shadow: 0 0 0 2px var(--amber-dim);
  }
  .text-input::placeholder { color: var(--text-dim); }
  .text-input:disabled { opacity: 0.4; cursor: not-allowed; }

  .send-btn {
    padding: 10px 20px;
    background: linear-gradient(135deg, var(--amber) 0%, #c89038 100%);
    color: var(--bg-void);
    border: none;
    border-radius: 4px;
    font-family: var(--mono);
    font-size: 10px;
    font-weight: 700;
    cursor: pointer;
    text-transform: uppercase;
    letter-spacing: 1px;
    transition: all 0.2s;
    box-shadow: 0 2px 8px rgba(212,160,70,0.2);
  }
  .send-btn:hover {
    background: linear-gradient(135deg, var(--amber-bright) 0%, var(--amber) 100%);
    box-shadow: 0 4px 16px rgba(212,160,70,0.3);
    transform: translateY(-1px);
  }
  .send-btn:active { transform: translateY(0); }
  .send-btn:disabled {
    background: var(--bg-surface);
    color: var(--text-dim);
    cursor: not-allowed;
    box-shadow: none;
    transform: none;
  }

  /* â”€â”€ Stats bar â”€â”€ */
  .stats-bar {
    display: flex;
    align-items: center;
    gap: 20px;
    padding: 8px 24px;
    border-top: 1px solid var(--border);
    background: var(--bg-deep);
    animation: statsReveal 0.6s ease-out 0.5s both;
  }
  @keyframes statsReveal {
    from { opacity: 0; }
    to { opacity: 1; }
  }

  .stat {
    display: flex;
    align-items: center;
    gap: 6px;
    font-size: 9px;
    color: var(--text-dim);
    text-transform: uppercase;
    letter-spacing: 0.5px;
  }
  .stat-val {
    color: var(--text-muted);
    font-variant-numeric: tabular-nums;
    min-width: 24px;
  }
  .stat-val.active { color: var(--amber); }
  .stat-sep {
    width: 1px;
    height: 10px;
    background: var(--border);
  }

  /* â”€â”€ Idle animation on scope â”€â”€ */
  .scope-idle-text {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    font-family: var(--display);
    font-size: 13px;
    font-weight: 300;
    color: var(--text-dim);
    letter-spacing: 2px;
    text-transform: uppercase;
    z-index: 2;
    pointer-events: none;
    transition: opacity 0.5s;
  }
  .scope-idle-text.hidden { opacity: 0; }

  /* â”€â”€ Responsive â”€â”€ */
  @media (max-width: 700px) {
    .app { max-width: 100%; }
    .header { padding: 10px 14px; }
    .main { padding: 0 14px; }
    .input-area { padding: 10px 14px; }
    .stats-bar { padding: 6px 14px; gap: 12px; flex-wrap: wrap; }
    .badge-model { display: none; }
    #waveform { height: 140px; }
  }
</style>
<script src="../../wasm/wasm_exec.js"></script>
<script src="../../wasm/ailang-repl.js"></script>
</head>
<body>

<div class="app">
  <!-- â”€â”€ Header â”€â”€ -->
  <div class="header">
    <div class="header-left">
      <div class="logo">AILANG<span>Ã—</span>Gemini Live</div>
      <span class="badge badge-model">gemini-2.5-flash-native-audio</span>
      <span class="badge badge-wss" id="wssBadge"><span class="dot"></span>WSS</span>
    </div>
    <div class="header-right">
      <button class="btn-sm" onclick="toggleConfig()" id="cfgBtn">Config</button>
      <button class="btn-sm" onclick="reconnect()" id="reconnBtn">Connect</button>
    </div>
  </div>

  <!-- â”€â”€ Config â”€â”€ -->
  <div class="config" id="configPanel">
    <div class="config-row">
      <label>API Key</label>
      <input type="password" class="config-input" id="apiKey"
             placeholder="Gemini API key (AI Studio)"
             value="">
    </div>
    <div class="config-row" style="margin-top:8px">
      <label>Voice</label>
      <select class="config-select" id="voiceSelect" onchange="saveConfig()">
        <option value="Sulafat">Sulafat (Warm)</option>
        <option value="Zephyr">Zephyr (Bright)</option>
        <option value="Puck">Puck (Upbeat)</option>
        <option value="Charon">Charon (Informative)</option>
        <option value="Kore">Kore (Firm)</option>
        <option value="Fenrir">Fenrir (Excitable)</option>
        <option value="Leda">Leda (Youthful)</option>
        <option value="Orus">Orus (Firm)</option>
        <option value="Aoede">Aoede (Breezy)</option>
        <option value="Callirrhoe">Callirrhoe (Easy-going)</option>
        <option value="Autonoe">Autonoe (Bright)</option>
        <option value="Enceladus">Enceladus (Breathy)</option>
        <option value="Iapetus">Iapetus (Clear)</option>
        <option value="Umbriel">Umbriel (Easy-going)</option>
        <option value="Algieba">Algieba (Smooth)</option>
        <option value="Despina">Despina (Smooth)</option>
        <option value="Erinome">Erinome (Clear)</option>
        <option value="Algenib">Algenib (Gravelly)</option>
        <option value="Rasalgethi">Rasalgethi (Informative)</option>
        <option value="Laomedeia">Laomedeia (Upbeat)</option>
        <option value="Achernar">Achernar (Soft)</option>
        <option value="Alnilam">Alnilam (Firm)</option>
        <option value="Schedar">Schedar (Even)</option>
        <option value="Gacrux">Gacrux (Mature)</option>
        <option value="Pulcherrima">Pulcherrima (Forward)</option>
        <option value="Achird">Achird (Friendly)</option>
        <option value="Zubenelgenubi">Zubenelgenubi (Casual)</option>
        <option value="Vindemiatrix">Vindemiatrix (Gentle)</option>
        <option value="Sadachbia">Sadachbia (Lively)</option>
        <option value="Sadaltager">Sadaltager (Knowledgeable)</option>
      </select>
    </div>
    <div class="config-warn">
      API calls go directly from your browser to Google's API. Key is stored in localStorage.
    </div>
  </div>

  <!-- â”€â”€ Main â”€â”€ -->
  <div class="main">
    <!-- Oscilloscope / Waveform -->
    <div class="scope-container">
      <div class="scope-frame" id="scopeFrame">
        <span class="scope-label">Audio Scope</span>
        <span class="scope-label-right" id="scopeRate">24kHz Â· 16-bit Â· mono</span>
        <span class="scope-idle-text" id="scopeIdle">awaiting signal</span>
        <canvas id="waveform"></canvas>
        <div class="vu-strip">
          <span class="vu-label">VU</span>
          <div class="vu-track"><div class="vu-fill" id="vuFill"></div></div>
          <span class="vu-db" id="vuDb">-âˆž dB</span>
        </div>
      </div>
    </div>

    <!-- Event log -->
    <div class="log-panel">
      <div class="log-header">
        <span class="log-title">Event Log</span>
        <button class="log-clear" onclick="clearLog()">Clear</button>
      </div>
      <div class="log-entries" id="logEntries"></div>
    </div>
  </div>

  <!-- â”€â”€ Input â”€â”€ -->
  <div class="input-area">
    <div class="input-row">
      <button class="mic-btn" id="micBtn" onclick="toggleMic()" title="Toggle microphone">ðŸŽ¤</button>
      <input type="text" class="text-input" id="textInput"
             placeholder="Type or speak to Gemini..."
             disabled>
      <button class="send-btn" id="sendBtn" onclick="sendText()" disabled>Send</button>
    </div>
  </div>

  <!-- â”€â”€ Stats â”€â”€ -->
  <div class="stats-bar">
    <div class="stat">
      <span>State</span>
      <span class="stat-val" id="fState">idle</span>
    </div>
    <div class="stat-sep"></div>
    <div class="stat">
      <span>Frames</span>
      <span class="stat-val" id="fFrames">0</span>
    </div>
    <div class="stat-sep"></div>
    <div class="stat">
      <span>Audio</span>
      <span class="stat-val" id="fBytes">0 B</span>
    </div>
    <div class="stat-sep"></div>
    <div class="stat">
      <span>Duration</span>
      <span class="stat-val" id="fDuration">0.0s</span>
    </div>
    <div class="stat-sep"></div>
    <div class="stat">
      <span>Latency</span>
      <span class="stat-val" id="fLatency">â€”</span>
    </div>
  </div>
</div>

<script>
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Gemini Live â€” AILANG WASM Streaming Demo
//
// Architecture: AILANG drives the WebSocket session via std/stream effects.
// JS registers effect handlers that bridge to the browser WebSocket API.
// AILANG emits events via println (IO effect) which JS intercepts to
// update the UI, play audio, etc.
//
// This is the same streaming model as the CLI (main.ail) â€” AILANG controls
// the session lifecycle. JS just provides transport and browser APIs.
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

let ws = null;             // WebSocket managed by Stream effect handler
let audioCtx = null;       // 48kHz for playback
let captureCtx = null;     // native rate for mic capture
let playbackNode = null;
let captureNode = null;
let isRecording = false;
let sessionReady = false;
let promptSentAt = 0;
let totalFrames = 0;
let totalBytes = 0;
let totalSamples = 0;
let lastPcmChunk = null;

// AILANG WASM state
let wasmEngine = null;
let wasmReady = false;
const WASM_MODULE = 'streaming/gemini_live/gemini_live_browser';

// â”€â”€ AILANG WASM Initialization â”€â”€
async function initWASM() {
  if (wasmReady) return;
  try {
    if (typeof AilangREPL === 'undefined') { console.warn('WASM not available'); return; }
    const repl = new AilangREPL();
    await repl.init('../../wasm/ailang.wasm');

    // Import stdlib modules needed by the AILANG module
    for (const lib of ['std/json', 'std/option', 'std/result', 'std/string', 'std/list', 'std/stream', 'std/io']) {
      repl.importModule(lib);
    }

    // Load the AILANG streaming module
    const resp = await fetch('../../ailang/streaming/gemini_live/gemini_live_browser.ail?v=' + Date.now());
    if (!resp.ok) throw new Error('Failed to fetch AILANG module');
    const code = await resp.text();
    const result = repl.loadModule(WASM_MODULE, code);
    if (!result.success) throw new Error(result.error);

    // Register effect handlers via native 2-arg API: (effectName, {op: fn, ...})
    // This also auto-grants capabilities (no separate grantCapability needed)
    const ioResult = window.ailangSetEffectHandler('IO', {
      println: (text) => {
        handleAILANGEvent(text);
        return '';
      }
    });
    console.log('IO effect handler result:', ioResult);

    // Register Stream effect handlers â€” bridge std/stream to browser WebSocket
    const streamResult = registerStreamHandlers();
    console.log('Stream effect handler result:', streamResult);

    wasmEngine = repl;
    wasmReady = true;
    console.log('AILANG Gemini Live module ready (streaming effects registered)');

    // Populate voices from AILANG catalog
    populateVoicesFromAILANG();
  } catch (e) {
    console.error('WASM init error:', e);
    addLog('err', 'WASM init failed: ' + e.message);
  }
}

// Register Stream effect handlers that bridge AILANG's std/stream to browser WebSocket API.
//
// KEY LIMITATION: ailangValueToJS converts AILANG closures to string representations,
// not callable JS functions. So the onEvent handler receives a string (the closure's
// display form), NOT something we can invoke. The AILANG runtime internally dispatches
// the callback â€” our runEventLoop just needs to deliver events in the format that
// the runtime expects, and the Go-side stream implementation handles the rest.
//
// The handlers use the native 2-arg API: ailangSetEffectHandler(effectName, {op: fn})
// which also auto-grants the Stream capability.
function registerStreamHandlers() {
  let eventLoopResolve = null;

  return window.ailangSetEffectHandler('Stream', {
    connect: (url, config) => {
      // AILANG calls connect(url, config) â€” we create a browser WebSocket
      return new Promise((resolve, reject) => {
        try {
          ws = new WebSocket(url);
          ws.onopen = () => {
            document.getElementById('wssBadge').classList.add('live');
            setState('connected');
            resolve('conn_1');
          };
          ws.onerror = (e) => {
            reject(new Error('WebSocket connection failed'));
          };
        } catch (e) {
          reject(e);
        }
      });
    },

    transmit: (conn, msg) => {
      if (ws && ws.readyState === 1) {
        ws.send(msg);
        return 'ok';
      }
      throw new Error('WebSocket not connected');
    },

    onEvent: (conn, handler) => {
      // handler arrives as a string (AILANG closure â†’ ailangValueToJS fallback).
      // The Go runtime handles callback dispatch internally â€” we just acknowledge.
      console.log('Stream onEvent registered (handler type:', typeof handler, ')');
      return '';
    },

    runEventLoop: (conn) => {
      // Return a Promise that resolves when WS closes.
      // The Go runtime's stream implementation calls onEvent's callback internally
      // when we deliver messages. But since ailangValueToJS can't preserve closures,
      // we need to process messages on the JS side and emit events via IO/println.
      //
      // WORKAROUND: Instead of trying to invoke the AILANG closure, we process
      // WebSocket messages directly in JS and emit events through the IO handler
      // (handleAILANGEvent). The AILANG startSession function will see the
      // runEventLoop resolve when the WS closes.
      return new Promise((resolve) => {
        eventLoopResolve = resolve;

        ws.onmessage = async (e) => {
          let text;
          if (typeof e.data === 'string') text = e.data;
          else if (e.data instanceof Blob) text = await e.data.text();
          else if (e.data instanceof ArrayBuffer) text = new TextDecoder().decode(e.data);
          else return;

          // Process the Gemini message directly in JS and emit via IO handler
          try {
            const parsed = JSON.parse(text);
            processGeminiMessage(parsed);
          } catch (err) {
            console.error('Message parse error:', err);
          }
        };

        ws.onclose = (e) => {
          document.getElementById('wssBadge').classList.remove('live');
          sessionReady = false;
          setState('closed');
          addLog('info', `WebSocket closed <span class="val">${e.code}</span>`);
          resolve('closed');
        };

        ws.onerror = (e) => {
          addLog('err', 'WebSocket error');
        };
      });
    },

    disconnect: (conn) => {
      if (ws) { ws.close(); ws = null; }
      return '';
    },

    status: (conn) => {
      if (!ws) return 'StreamClosed';
      switch (ws.readyState) {
        case 0: return 'Connecting';
        case 1: return 'Open';
        case 2: return 'Closing';
        default: return 'StreamClosed';
      }
    }
  });
}

// Process Gemini WebSocket messages directly in JS.
// This is necessary because AILANG closures can't be invoked from JS via
// ailangValueToJS (converts them to strings, not callable functions).
// The session lifecycle (connect â†’ setup â†’ event loop â†’ disconnect) is still
// driven by AILANG's startSession. But message dispatch happens here in JS
// using AILANG's pure helpers for protocol construction (buildTextMessage, etc).
let pendingInitialPrompt = null;

function processGeminiMessage(msg) {
  if (msg.setupComplete) {
    sessionReady = true;
    setState('ready');
    addLog('ok', '<span class="hl">Setup complete</span> â€” session ready (AILANG streaming)');
    document.getElementById('sendBtn').disabled = false;
    document.getElementById('textInput').disabled = false;
    document.getElementById('textInput').focus();
    document.getElementById('scopeIdle').textContent = 'ready for input';

    // Send initial prompt if one was provided (AILANG built the setup, JS sends the prompt)
    if (pendingInitialPrompt && ws && ws.readyState === 1) {
      const textMsg = callAILANG('buildTextMessage', pendingInitialPrompt);
      if (textMsg) {
        ws.send(textMsg);
        addLog('info', 'Sent: <span class="val">' + escapeHtml(pendingInitialPrompt) + '</span>');
        setState('streaming');
        promptSentAt = Date.now();
      }
      pendingInitialPrompt = null;
    }
    return;
  }

  if (msg.serverContent) {
    const sc = msg.serverContent;

    // Input transcription
    if (sc.inputTranscription && sc.inputTranscription.text) {
      const t = sc.inputTranscription.text;
      if (t.length > 0) {
        addLog('info', 'You said: <span class="val">' + escapeHtml(t) + '</span>');
      }
    }

    // Output transcription
    if (sc.outputTranscription && sc.outputTranscription.text) {
      const t = sc.outputTranscription.text;
      if (t.length > 0) {
        addLog('info', 'Model: <span class="val">' + escapeHtml(t) + '</span>');
      }
    }

    // Model turn with audio/text parts
    if (sc.modelTurn && sc.modelTurn.parts) {
      for (const part of sc.modelTurn.parts) {
        if (part.inlineData && part.inlineData.data) {
          handleAudioFrame(part.inlineData.data);
        }
        if (part.text) {
          addLog('info', 'Transcript: <span class="val">' + escapeHtml(part.text) + '</span>');
        }
      }
    }

    // Turn complete
    if (sc.turnComplete) {
      sessionReady = true;
      setState('ready');
      addLog('ok', '<span class="hl">Turn complete</span> â€” <span class="val">' + totalFrames + '</span> frames, <span class="val">' + fmtBytes(totalBytes) + '</span>');
      document.getElementById('sendBtn').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('textInput').focus();
    }
  }

  if (msg.toolCall) {
    addLog('warn', 'Tool call: <span class="val">' + JSON.stringify(msg.toolCall.functionCalls || []).substring(0, 120) + '</span>');
  }
}

// Handle AILANG events emitted via println (IO effect handler)
// AILANG emits structured JSON events; we parse and render to UI
function handleAILANGEvent(text) {
  let event;
  try { event = JSON.parse(text); } catch {
    // Plain text â€” just log it
    addLog('info', escapeHtml(text));
    return;
  }

  switch (event.type) {
    case 'log':
      addLog('info', escapeHtml(event.text || ''));
      break;

    case 'setup':
      sessionReady = true;
      document.getElementById('sendBtn').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('textInput').focus();
      setState('ready');
      addLog('ok', '<span class="hl">Setup complete</span> â€” session ready (AILANG streaming)');
      document.getElementById('scopeIdle').textContent = 'ready for input';
      break;

    case 'sent':
      addLog('info', 'AILANG sent: <span class="val">' + escapeHtml(event.text || '') + '</span>');
      setState('streaming');
      break;

    case 'turnComplete':
      setState('ready');
      addLog('ok', '<span class="hl">Turn complete</span> â€” <span class="val">' + totalFrames + '</span> frames, <span class="val">' + fmtBytes(totalBytes) + '</span>');
      document.getElementById('sendBtn').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('textInput').focus();
      break;

    case 'inputTranscript':
      if (event.text) addLog('info', 'You said: <span class="val">' + escapeHtml(event.text) + '</span>');
      break;

    case 'outputTranscript':
      if (event.text) addLog('info', 'Model: <span class="val">' + escapeHtml(event.text) + '</span>');
      break;

    case 'modelTurn':
      if (event.parts && Array.isArray(event.parts)) {
        event.parts.forEach(part => {
          if (part.text) {
            addLog('info', 'Transcript: <span class="val">' + escapeHtml(part.text) + '</span>');
          }
          if (part.inlineData && part.inlineData.data) {
            handleAudioFrame(part.inlineData.data);
          }
        });
      }
      break;

    case 'toolCall':
      addLog('warn', 'Tool call: <span class="val">' + JSON.stringify(event.calls).substring(0, 120) + '</span>');
      break;

    case 'opened':
      addLog('ok', 'WebSocket opened');
      break;

    case 'closed':
      addLog('info', 'Session closed (code: ' + (event.code || '?') + ')');
      break;

    case 'error':
      addLog('err', 'AILANG: ' + escapeHtml(event.text || 'unknown error'));
      break;

    default:
      addLog('info', 'AILANG event: <span class="val">' + event.type + '</span>');
  }
}

// Call a pure AILANG function (for message construction)
function callAILANG(funcName, ...args) {
  if (!wasmReady) return null;
  try {
    let val;
    if (args.length === 0) {
      // Zero-arg AILANG functions: repl.call returns <function>, use eval instead
      val = wasmEngine.eval(funcName + '()');
    } else {
      const result = wasmEngine.call(WASM_MODULE, funcName, ...args);
      if (!result.success) { console.error('AILANG error:', result.error); return null; }
      val = result.result || '';
    }
    // Strip type annotation (e.g., '... :: string')
    const typeMatch = val.match(/^(.+)\s+::\s+\w+$/s);
    if (typeMatch) val = typeMatch[1];
    // Unwrap AILANG string quotes
    if (val.startsWith('"') && val.endsWith('"')) {
      try { val = JSON.parse(val); } catch { val = val.slice(1, -1); }
    }
    return val;
  } catch (e) {
    console.error('AILANG call error:', e);
    return null;
  }
}

function populateVoicesFromAILANG() {
  if (!wasmReady) return;
  try {
    // Zero-arg AILANG functions return <function> via repl.call() â€” use eval instead
    wasmEngine.importModule(WASM_MODULE);
    let raw = wasmEngine.eval('voiceCatalog()');
    console.log('voiceCatalog raw:', typeof raw, raw ? raw.substring(0, 120) : 'null');

    // Strip type annotation (e.g., '... :: string')
    const typeMatch = raw.match(/^(.+)\s+::\s+\w+$/s);
    if (typeMatch) raw = typeMatch[1];

    // AILANG wraps strings in quotes â€” unwrap to get the JSON
    if (raw.startsWith('"') && raw.endsWith('"')) {
      try { raw = JSON.parse(raw); } catch { raw = raw.slice(1, -1); }
    }

    const voices = JSON.parse(raw);
    const select = document.getElementById('voiceSelect');
    const current = select.value;
    select.innerHTML = '';
    voices.forEach(v => {
      const opt = document.createElement('option');
      opt.value = v.name;
      opt.textContent = `${v.name} (${v.desc})`;
      select.appendChild(opt);
    });
    const saved = localStorage.getItem('gemini-live-voice');
    if (saved) select.value = saved;
    else {
      let dv = wasmEngine.eval('defaultVoice()');
      const dvMatch = dv.match(/^"(.+)"\s+::\s+\w+$/s);
      if (dvMatch) dv = dvMatch[1];
      else if (dv.startsWith('"') && dv.endsWith('"')) dv = dv.slice(1, -1);
      select.value = current || dv || 'Sulafat';
    }
  } catch (e) { console.error('Voice catalog parse error:', e); }
}

// â”€â”€ Config â”€â”€
function toggleConfig() {
  document.getElementById('configPanel').classList.toggle('open');
}

function loadConfig() {
  if (!localStorage.getItem('gemini-api-key') && localStorage.getItem('gemini_live_key'))
    localStorage.setItem('gemini-api-key', localStorage.getItem('gemini_live_key'));
  const saved = localStorage.getItem('gemini-api-key');
  if (saved) document.getElementById('apiKey').value = saved;
  const voice = localStorage.getItem('gemini-live-voice');
  if (voice) document.getElementById('voiceSelect').value = voice;
}

function saveConfig() {
  const key = document.getElementById('apiKey').value.trim();
  if (key) localStorage.setItem('gemini-api-key', key);
  localStorage.setItem('gemini-live-voice', document.getElementById('voiceSelect').value);
}

// â”€â”€ Logging â”€â”€
function addLog(type, html) {
  const el = document.createElement('div');
  el.className = 'log-entry';
  const now = new Date();
  const ts = String(now.getHours()).padStart(2,'0') + ':' +
             String(now.getMinutes()).padStart(2,'0') + ':' +
             String(now.getSeconds()).padStart(2,'0') + '.' +
             String(now.getMilliseconds()).padStart(3,'0').slice(0,2);
  el.innerHTML = `<span class="log-time">${ts}</span><span class="log-dot ${type}"></span><span class="log-text">${html}</span>`;
  const container = document.getElementById('logEntries');
  container.appendChild(el);
  container.scrollTop = container.scrollHeight;
}
function clearLog() { document.getElementById('logEntries').innerHTML = ''; }

// â”€â”€ Format helpers â”€â”€
function fmtBytes(b) {
  if (b < 1024) return b + ' B';
  if (b < 1048576) return (b / 1024).toFixed(1) + ' KB';
  return (b / 1048576).toFixed(2) + ' MB';
}
function updateStats() {
  document.getElementById('fFrames').textContent = totalFrames;
  document.getElementById('fBytes').textContent = fmtBytes(totalBytes);
  const dur = totalSamples / 24000;
  document.getElementById('fDuration').textContent = dur.toFixed(1) + 's';
  if (totalFrames > 0) {
    document.getElementById('fFrames').classList.add('active');
    document.getElementById('fBytes').classList.add('active');
    document.getElementById('fDuration').classList.add('active');
  }
}
function setState(s) {
  const el = document.getElementById('fState');
  el.textContent = s;
  el.classList.toggle('active', s !== 'idle' && s !== 'closed');
}

// â”€â”€ Connect: AILANG drives the session via std/stream effects â”€â”€
async function reconnect() {
  if (ws) { ws.close(); ws = null; }
  const key = document.getElementById('apiKey').value.trim() || localStorage.getItem('gemini-api-key');
  if (!key) { toggleConfig(); addLog('warn', 'Enter your Gemini API key'); return; }
  saveConfig();

  if (!wasmReady) {
    addLog('err', 'AILANG WASM not loaded â€” cannot start streaming session');
    return;
  }

  sessionReady = false;
  totalFrames = 0; totalBytes = 0; totalSamples = 0;
  updateStats();
  setState('connecting');

  document.getElementById('sendBtn').disabled = true;
  document.getElementById('textInput').disabled = true;

  // Init audio on first user gesture
  await initAudio();

  const voice = document.getElementById('voiceSelect').value;
  const instruction = callAILANG('defaultInstruction') || 'You are a friendly assistant.';

  // Store initial prompt â€” processGeminiMessage sends it after setupComplete
  pendingInitialPrompt = 'Hello!';
  promptSentAt = Date.now();

  addLog('info', 'Starting AILANG streaming session...');

  // AILANG drives the session lifecycle: connect â†’ transmit(setup) â†’ onEvent â†’ runEventLoop â†’ disconnect
  // Message dispatch happens in JS (processGeminiMessage) because AILANG closures
  // can't be invoked from JS via the WASM bridge (ailangValueToJS limitation).
  try {
    streamingSession = wasmEngine.callAsync(WASM_MODULE, 'startSession', key, voice, instruction, 'Hello!');
    const result = await streamingSession;
    console.log('AILANG session ended:', result);
    addLog('info', 'AILANG session ended');
  } catch (e) {
    console.error('AILANG session error:', e);
    addLog('err', 'AILANG session error: ' + e.message);
  }
  streamingSession = null;
}

// Audio frame processing (browser-specific â€” stays in JS)
function handleAudioFrame(b64) {
  if (totalFrames === 0 && promptSentAt > 0) {
    const latency = Date.now() - promptSentAt;
    document.getElementById('fLatency').textContent = latency + 'ms';
    document.getElementById('fLatency').classList.add('active');
    addLog('info', 'First audio in <span class="val">' + latency + 'ms</span>');
  }
  totalFrames++;
  const rawBytes = atob(b64);
  const byteLen = rawBytes.length;
  totalBytes += byteLen;
  const buf = new ArrayBuffer(byteLen);
  const view = new Uint8Array(buf);
  for (let i = 0; i < byteLen; i++) view[i] = rawBytes.charCodeAt(i);
  const pcm16 = new Int16Array(buf);
  totalSamples += pcm16.length;
  enqueueAudio(pcm16);
  lastPcmChunk = pcm16;
  updateVU(pcm16);
  document.getElementById('scopeFrame').classList.add('active');
  document.getElementById('scopeIdle').classList.add('hidden');
  if (totalFrames <= 3 || totalFrames % 5 === 0) {
    addLog('audio', '<span class="hl">Audio</span> frame <span class="val">#' + totalFrames + '</span> â€” ' + fmtBytes(byteLen) + ' (' + pcm16.length + ' samples)');
  }
  updateStats();
}

// â”€â”€ Audio playback â”€â”€
async function initAudio() {
  if (audioCtx) return;
  audioCtx = new AudioContext({ sampleRate: 48000 });
  await audioCtx.audioWorklet.addModule('../shared/audio-worklet.js');
  playbackNode = new AudioWorkletNode(audioCtx, 'pcm-playback', {
    processorOptions: { sourceRate: 24000 }
  });
  playbackNode.connect(audioCtx.destination);
  addLog('ok', 'Audio engine initialized â€” <span class="val">24kHz â†’ 48kHz</span>');
}
function enqueueAudio(pcm16) {
  if (!playbackNode) return;
  playbackNode.port.postMessage({ type: 'enqueue', pcmData: pcm16.buffer }, [pcm16.buffer]);
}

// â”€â”€ VU meter â”€â”€
function updateVU(pcm16) {
  let sum = 0;
  for (let i = 0; i < pcm16.length; i++) { const s = pcm16[i] / 32768; sum += s * s; }
  const rms = Math.sqrt(sum / pcm16.length);
  const db = rms > 0 ? 20 * Math.log10(rms) : -60;
  const clamped = Math.max(-60, Math.min(0, db));
  const pct = ((clamped + 60) / 60) * 100;
  document.getElementById('vuFill').style.width = pct + '%';
  document.getElementById('vuDb').textContent = db > -60 ? db.toFixed(1) + ' dB' : '-âˆž dB';
}

// â”€â”€ Send text â€” uses AILANG buildTextMessage, sends via WS managed by AILANG â”€â”€
async function sendText() {
  const input = document.getElementById('textInput');
  const text = input.value.trim();
  if (!text || !ws || ws.readyState !== 1 || !sessionReady) return;

  await initAudio();
  totalFrames = 0; totalBytes = 0; totalSamples = 0;
  promptSentAt = Date.now();
  document.getElementById('fLatency').textContent = 'â€”';
  document.getElementById('fLatency').classList.remove('active');
  updateStats();
  if (playbackNode) playbackNode.port.postMessage({ command: 'clear' });

  addLog('info', 'Sending: <span class="val">' + escapeHtml(text) + '</span>');

  // Build message via AILANG WASM, send through the AILANG-managed WebSocket
  const msgJson = callAILANG('buildTextMessage', text);
  ws.send(msgJson || JSON.stringify({
    clientContent: { turns: [{ role: 'user', parts: [{ text }] }], turnComplete: true }
  }));

  input.value = '';
  input.disabled = true;
  document.getElementById('sendBtn').disabled = true;
  setState('streaming');
  document.getElementById('scopeIdle').textContent = 'receiving audio';
  document.getElementById('scopeIdle').classList.remove('hidden');
  setTimeout(() => document.getElementById('scopeIdle').classList.add('hidden'), 1500);
}

function escapeHtml(s) {
  const d = document.createElement('div');
  d.textContent = s;
  return d.innerHTML;
}

// â”€â”€ Microphone capture â”€â”€
async function toggleMic() {
  const btn = document.getElementById('micBtn');
  if (isRecording) {
    isRecording = false;
    btn.classList.remove('active');
    if (captureNode) captureNode.port.postMessage({ command: 'stop' });
    addLog('info', 'Mic stopped');
    return;
  }
  await initAudio();
  if (!captureCtx) {
    captureCtx = new AudioContext();
    await captureCtx.audioWorklet.addModule('../shared/audio-worklet.js');
  }
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const source = captureCtx.createMediaStreamSource(stream);
    captureNode = new AudioWorkletNode(captureCtx, 'pcm-capture', {
      processorOptions: { targetRate: 16000 }
    });
    source.connect(captureNode);
    captureNode.port.onmessage = (e) => {
      if (e.data.type === 'pcm-chunk' && ws && ws.readyState === 1 && sessionReady) {
        const bytes = new Uint8Array(e.data.pcmData);
        let b = '';
        for (let i = 0; i < bytes.length; i++) b += String.fromCharCode(bytes[i]);
        const b64 = btoa(b);
        // Build audio chunk via AILANG WASM, send via AILANG-managed WebSocket
        const chunkJson = callAILANG('buildAudioChunk', b64);
        ws.send(chunkJson || JSON.stringify({
          realtimeInput: { mediaChunks: [{ mimeType: 'audio/pcm;rate=16000', data: b64 }] }
        }));
      }
    };
    isRecording = true;
    btn.classList.add('active');
    addLog('ok', 'Mic active â€” streaming audio at 16kHz');
    if (!ws || ws.readyState !== 1) reconnect();
  } catch (e) {
    addLog('err', 'Mic access denied: ' + e.message);
  }
}

// â”€â”€ Waveform visualization â”€â”€
const canvas = document.getElementById('waveform');
const ctx = canvas.getContext('2d');
let animId = null;
let waveData = new Float32Array(1024).fill(0);
let targetWave = new Float32Array(1024).fill(0);

function resizeCanvas() {
  const rect = canvas.parentElement.getBoundingClientRect();
  const dpr = window.devicePixelRatio || 1;
  canvas.width = rect.width * dpr;
  canvas.height = 180 * dpr;
  canvas.style.height = '180px';
  ctx.setTransform(dpr, 0, 0, dpr, 0, 0);
}

function drawGrid() {
  const w = canvas.width / (window.devicePixelRatio || 1);
  const h = 180;

  // Subtle grid lines
  ctx.strokeStyle = 'rgba(212,160,70,0.04)';
  ctx.lineWidth = 0.5;

  // Horizontal grid
  for (let i = 1; i < 6; i++) {
    const y = (h / 6) * i;
    ctx.beginPath();
    ctx.moveTo(0, y);
    ctx.lineTo(w, y);
    ctx.stroke();
  }

  // Vertical grid
  const cols = Math.floor(w / 40);
  for (let i = 1; i < cols; i++) {
    const x = (w / cols) * i;
    ctx.beginPath();
    ctx.moveTo(x, 0);
    ctx.lineTo(x, h);
    ctx.stroke();
  }

  // Center line (brighter)
  ctx.strokeStyle = 'rgba(212,160,70,0.08)';
  ctx.lineWidth = 1;
  ctx.beginPath();
  ctx.moveTo(0, h / 2);
  ctx.lineTo(w, h / 2);
  ctx.stroke();
}

function drawWaveform() {
  const w = canvas.width / (window.devicePixelRatio || 1);
  const h = 180;
  const mid = h / 2;

  ctx.clearRect(0, 0, w, h);
  drawGrid();

  // Interpolate toward target
  for (let i = 0; i < waveData.length; i++) {
    waveData[i] += (targetWave[i] - waveData[i]) * 0.18;
  }

  // Glow layer
  ctx.shadowColor = 'rgba(212,160,70,0.3)';
  ctx.shadowBlur = 8;
  ctx.strokeStyle = 'rgba(212,160,70,0.25)';
  ctx.lineWidth = 3;
  ctx.beginPath();
  for (let i = 0; i < w; i++) {
    const idx = Math.floor((i / w) * waveData.length);
    const y = mid + waveData[idx] * mid * 0.85;
    if (i === 0) ctx.moveTo(i, y);
    else ctx.lineTo(i, y);
  }
  ctx.stroke();

  // Main line
  ctx.shadowColor = 'transparent';
  ctx.shadowBlur = 0;
  ctx.strokeStyle = 'rgba(212,160,70,0.7)';
  ctx.lineWidth = 1.5;
  ctx.beginPath();
  for (let i = 0; i < w; i++) {
    const idx = Math.floor((i / w) * waveData.length);
    const y = mid + waveData[idx] * mid * 0.85;
    if (i === 0) ctx.moveTo(i, y);
    else ctx.lineTo(i, y);
  }
  ctx.stroke();

  // Bright peak dots
  ctx.fillStyle = 'rgba(232,184,90,0.6)';
  for (let i = 0; i < w; i += 6) {
    const idx = Math.floor((i / w) * waveData.length);
    const val = Math.abs(waveData[idx]);
    if (val > 0.3) {
      const y = mid + waveData[idx] * mid * 0.85;
      const r = val * 1.5;
      ctx.beginPath();
      ctx.arc(i, y, r, 0, Math.PI * 2);
      ctx.fill();
    }
  }

  // Decay toward silence
  for (let i = 0; i < targetWave.length; i++) {
    targetWave[i] *= 0.97;
  }

  animId = requestAnimationFrame(drawWaveform);
}

// Feed PCM into waveform target
function feedWaveform(pcm16) {
  const len = targetWave.length;
  const step = Math.max(1, Math.floor(pcm16.length / len));
  for (let i = 0; i < len; i++) {
    const idx = Math.min(i * step, pcm16.length - 1);
    targetWave[i] = pcm16[idx] / 32768;
  }
}

// Watch for new PCM data
let lastFedFrame = 0;
setInterval(() => {
  if (lastPcmChunk && totalFrames > lastFedFrame) {
    feedWaveform(lastPcmChunk);
    lastFedFrame = totalFrames;
  }
}, 50);

// â”€â”€ Keyboard â”€â”€
document.getElementById('textInput').addEventListener('keydown', (e) => {
  if (e.key === 'Enter' && !e.shiftKey) {
    e.preventDefault();
    sendText();
  }
});

// â”€â”€ Init â”€â”€
window.addEventListener('load', async () => {
  loadConfig();
  resizeCanvas();
  drawWaveform();

  addLog('info', 'AILANG Ã— Gemini Live â€” loading WASM streaming engine...');
  await initWASM();
  if (wasmReady) {
    addLog('ok', 'AILANG WASM loaded â€” <span class="hl">std/stream effects</span> bridged to browser WebSocket');
    addLog('info', 'Session lifecycle driven by AILANG (connect â†’ setup â†’ event loop)');
  } else {
    addLog('err', 'AILANG WASM failed to load â€” streaming requires AILANG');
  }
  addLog('info', 'Model: <span class="hl">gemini-2.5-flash-native-audio</span>');
  addLog('info', 'Click <span class="val">Connect</span> to start');
});

window.addEventListener('resize', resizeCanvas);
</script>
<script src="../shared/nav.js"></script>
</body>
</html>
